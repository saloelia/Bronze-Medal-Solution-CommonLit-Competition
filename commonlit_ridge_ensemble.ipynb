{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DASEjRHocTwG",
        "outputId": "a5b52d15-cfd3-4dc0-e777-76d78879bba9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import GroupKFold\n",
        "import zipfile\n",
        "from sklearn.linear_model import Ridge,LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.svm import SVR\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n"
      ],
      "metadata": {
        "id": "S03lB57actEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(\"/content/drive/MyDrive/CommonLit/commont-lit-train.csv\")\n",
        "\n",
        "gkf = GroupKFold(n_splits=4)\n",
        "for i, (_, val_index) in enumerate(gkf.split(train, groups=train[\"prompt_id\"])):\n",
        "    train.loc[val_index, \"fold\"] = i\n"
      ],
      "metadata": {
        "id": "zptn3BC3cxWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "albert = pd.read_csv(\"/content/drive/MyDrive/CommonLit/albert-base-v2/train-predictions.csv\")\n",
        "electra = pd.read_csv(\"/content/drive/MyDrive/CommonLit/electra-base-discriminator/train-predictions.csv\")\n",
        "roberta = pd.read_csv(\"/content/drive/MyDrive/CommonLit/roberta-base-squad2/train-predictions.csv\")\n",
        "deberta = pd.read_csv(\"/content/drive/MyDrive/CommonLit/deberta-v3-base/train-predictions.csv\")\n",
        "xlm = pd.read_csv(\"/content/drive/MyDrive/CommonLit/xlm-roberta-base/train-predictions.csv\")\n",
        "funnel =  pd.read_csv(\"/content/drive/MyDrive/CommonLit/funnel-medium-base/train-predictions.csv\")\n",
        "mpnet = pd.read_csv(\"/content/drive/MyDrive/CommonLit/all-mpnet-base-v2/train-predictions.csv\")\n",
        "distilbert_base = pd.read_csv(\"/content/drive/MyDrive/CommonLit/distilbert-base-uncased/train-predictions.csv\")\n",
        "distilbert_base_sst = pd.read_csv(\"/content/drive/MyDrive/CommonLit/distilbert-base-uncased-finetuned-sst-2-english/train-predictions.csv\")\n",
        "bert_base =  pd.read_csv(\"/content/drive/MyDrive/CommonLit/bert-base-uncased/train-predictions.csv\")\n",
        "deberta_v3_large = pd.read_csv(\"/content/drive/MyDrive/CommonLit/deberta-v3-large/train-predictions_1.csv\")\n",
        "xlm_roberta_large = pd.read_csv(\"/content/drive/MyDrive/CommonLit/xlm-roberta-large/train-predictions_1.csv\")\n",
        "roberta_large = pd.read_csv(\"/content/drive/MyDrive/CommonLit/roberta-large/train-predictions_1.csv\")\n",
        "bert_large_cased = pd.read_csv(\"/content/drive/MyDrive/CommonLit/bert-large-cased/train-predictions_1.csv\")\n",
        "\n",
        "albert_pred = albert[['content_multi_pred','wording_multi_pred']].copy()\n",
        "electra_pred = electra[['content_multi_pred','wording_multi_pred']].copy()\n",
        "roberta_pred = roberta[['content_multi_pred','wording_multi_pred']].copy()\n",
        "deberta_pred = deberta[['content_multi_pred','wording_multi_pred']].copy()\n",
        "xlm_pred = xlm[['content_multi_pred','wording_multi_pred']].copy()\n",
        "funnel_pred = funnel[['content_multi_pred','wording_multi_pred']].copy()\n",
        "mpnet_pred = mpnet[['content_multi_pred','wording_multi_pred']].copy()\n",
        "distilbert_base_pred = distilbert_base[['content_multi_pred','wording_multi_pred']].copy()\n",
        "distilbert_base_sst_pred = distilbert_base_sst[['content_multi_pred','wording_multi_pred']].copy()\n",
        "bert_base_pred = bert_base[['content_multi_pred','wording_multi_pred']].copy()\n",
        "deberta_v3_large_pred = deberta_v3_large[['content_multi_pred','wording_multi_pred']].copy()\n",
        "xlm_roberta_large_pred = xlm_roberta_large[['content_multi_pred','wording_multi_pred']].copy()\n",
        "roberta_large_pred = roberta_large[['content_multi_pred','wording_multi_pred']].copy()\n",
        "bert_large_cased_pred = bert_large_cased[['content_multi_pred','wording_multi_pred']].copy()\n",
        "\n",
        "albert_pred = albert_pred.rename(columns={\"content_multi_pred\":\"albert_content\",\"wording_multi_pred\":\"albert_wording\"})\n",
        "electra_pred = electra_pred.rename(columns={\"content_multi_pred\":\"electra_content\",\"wording_multi_pred\":\"electra_wording\"})\n",
        "roberta_pred = roberta_pred.rename(columns={\"content_multi_pred\":\"roberta_content\",\"wording_multi_pred\":\"roberta_wording\"})\n",
        "deberta_pred = deberta_pred.rename(columns={\"content_multi_pred\":\"deberta_content\",\"wording_multi_pred\":\"deberta_wording\"})\n",
        "xlm_pred = xlm_pred.rename(columns={\"content_multi_pred\":\"xlm_content\",\"wording_multi_pred\":\"xlm_wording\"})\n",
        "funnel_pred = funnel_pred.rename(columns={\"content_multi_pred\":\"funnel_content\",\"wording_multi_pred\":\"funnel_wording\"})\n",
        "mpnet_pred = mpnet_pred.rename(columns={\"content_multi_pred\":\"mpnet_content\",\"wording_multi_pred\":\"mpnet_wording\"})\n",
        "distilbert_base_pred = distilbert_base_pred.rename(columns={\"content_multi_pred\":\"distilbert_content\",\"wording_multi_pred\":\"distilbert_wording\"})\n",
        "distilbert_base_sst_pred = distilbert_base_sst_pred.rename(columns={\"content_multi_pred\":\"distilbert_sst_content\",\"wording_multi_pred\":\"distilbert_sst_wording\"})\n",
        "bert_base_pred = bert_base_pred.rename(columns={\"content_multi_pred\":\"bert_content\",\"wording_multi_pred\":\"bert_wording\"})\n",
        "deberta_v3_large_pred = deberta_v3_large_pred.rename(columns={\"content_multi_pred\":\"deberta_v3_large_content\",\"wording_multi_pred\":\"deberta_v3_large_wording\"})\n",
        "xlm_roberta_large_pred = xlm_roberta_large_pred.rename(columns={\"content_multi_pred\":\"xlm_roberta_large_content\",\"wording_multi_pred\":\"xlm_roberta_large_wording\"})\n",
        "roberta_large_pred = roberta_large_pred.rename(columns={\"content_multi_pred\":\"roberta_large_content\",\"wording_multi_pred\":\"roberta_large_wording\"})\n",
        "bert_large_cased_pred = bert_large_cased_pred.rename(columns={\"content_multi_pred\":\"bert_large_cased_content\",\"wording_multi_pred\":\"bert_large_cased_wording\"})"
      ],
      "metadata": {
        "id": "X9WvoWtQgXze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_preds = pd.concat([train[['content','wording','fold']].copy(),\n",
        "                       xlm_pred,funnel_pred,mpnet_pred,deberta_v3_large_pred],axis=1)\n",
        "all_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "rOT0VoH0SDZd",
        "outputId": "854c692b-1ad4-4505-85fd-05dc806f46fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       content   wording  fold  xlm_content  xlm_wording  funnel_content  \\\n",
              "0     0.205683  0.380538   3.0     0.048096     0.604004       -0.164185   \n",
              "1    -0.548304  0.506755   2.0    -0.484619    -0.054352       -0.560059   \n",
              "2     3.128928  4.231226   1.0     2.257812     1.947266        1.828125   \n",
              "3    -0.210614 -0.471415   1.0    -1.192383    -1.055664       -0.964844   \n",
              "4     3.272894  3.219757   3.0     2.115234     1.890625        2.437500   \n",
              "...        ...       ...   ...          ...          ...             ...   \n",
              "7160  0.205683  0.380538   2.0    -0.023285    -0.028091       -0.281982   \n",
              "7161 -0.308448  0.048171   1.0    -0.574707    -0.354004       -0.511230   \n",
              "7162 -1.408180 -0.493603   1.0    -0.751953    -0.255859       -1.231445   \n",
              "7163 -0.393310  0.627128   0.0     0.258301     0.458008        0.062286   \n",
              "7164  1.771596  0.547742   2.0     0.915527     0.829590        0.728027   \n",
              "\n",
              "      funnel_wording  mpnet_content  mpnet_wording  deberta_v3_large_content  \\\n",
              "0           0.444824       0.245850       1.056641                  0.060547   \n",
              "1          -0.255615      -0.372070       0.034302                 -0.770508   \n",
              "2           1.658203       2.093750       2.015625                  2.558594   \n",
              "3          -0.855957      -0.900879      -0.801758                 -0.699219   \n",
              "4           2.500000       2.095703       2.023438                  1.975586   \n",
              "...              ...            ...            ...                       ...   \n",
              "7160       -0.092346      -0.187500       0.138306                 -0.028366   \n",
              "7161       -0.302979      -0.427734      -0.218628                 -0.197021   \n",
              "7162       -1.173828      -0.592773      -0.391602                 -0.518066   \n",
              "7163        0.427246      -0.195557       0.263184                 -0.023483   \n",
              "7164        0.502441       0.919922       0.443359                  0.835449   \n",
              "\n",
              "      deberta_v3_large_wording  \n",
              "0                     0.817871  \n",
              "1                    -0.442871  \n",
              "2                     2.748047  \n",
              "3                    -0.434326  \n",
              "4                     2.103516  \n",
              "...                        ...  \n",
              "7160                  0.094543  \n",
              "7161                 -0.052368  \n",
              "7162                 -0.248413  \n",
              "7163                  0.413086  \n",
              "7164                  0.739258  \n",
              "\n",
              "[7165 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-23dc0c67-4fa6-4f83-9071-37ff990ede89\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>wording</th>\n",
              "      <th>fold</th>\n",
              "      <th>xlm_content</th>\n",
              "      <th>xlm_wording</th>\n",
              "      <th>funnel_content</th>\n",
              "      <th>funnel_wording</th>\n",
              "      <th>mpnet_content</th>\n",
              "      <th>mpnet_wording</th>\n",
              "      <th>deberta_v3_large_content</th>\n",
              "      <th>deberta_v3_large_wording</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.205683</td>\n",
              "      <td>0.380538</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.048096</td>\n",
              "      <td>0.604004</td>\n",
              "      <td>-0.164185</td>\n",
              "      <td>0.444824</td>\n",
              "      <td>0.245850</td>\n",
              "      <td>1.056641</td>\n",
              "      <td>0.060547</td>\n",
              "      <td>0.817871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.548304</td>\n",
              "      <td>0.506755</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-0.484619</td>\n",
              "      <td>-0.054352</td>\n",
              "      <td>-0.560059</td>\n",
              "      <td>-0.255615</td>\n",
              "      <td>-0.372070</td>\n",
              "      <td>0.034302</td>\n",
              "      <td>-0.770508</td>\n",
              "      <td>-0.442871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.128928</td>\n",
              "      <td>4.231226</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.257812</td>\n",
              "      <td>1.947266</td>\n",
              "      <td>1.828125</td>\n",
              "      <td>1.658203</td>\n",
              "      <td>2.093750</td>\n",
              "      <td>2.015625</td>\n",
              "      <td>2.558594</td>\n",
              "      <td>2.748047</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.210614</td>\n",
              "      <td>-0.471415</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.192383</td>\n",
              "      <td>-1.055664</td>\n",
              "      <td>-0.964844</td>\n",
              "      <td>-0.855957</td>\n",
              "      <td>-0.900879</td>\n",
              "      <td>-0.801758</td>\n",
              "      <td>-0.699219</td>\n",
              "      <td>-0.434326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.272894</td>\n",
              "      <td>3.219757</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.115234</td>\n",
              "      <td>1.890625</td>\n",
              "      <td>2.437500</td>\n",
              "      <td>2.500000</td>\n",
              "      <td>2.095703</td>\n",
              "      <td>2.023438</td>\n",
              "      <td>1.975586</td>\n",
              "      <td>2.103516</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7160</th>\n",
              "      <td>0.205683</td>\n",
              "      <td>0.380538</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-0.023285</td>\n",
              "      <td>-0.028091</td>\n",
              "      <td>-0.281982</td>\n",
              "      <td>-0.092346</td>\n",
              "      <td>-0.187500</td>\n",
              "      <td>0.138306</td>\n",
              "      <td>-0.028366</td>\n",
              "      <td>0.094543</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7161</th>\n",
              "      <td>-0.308448</td>\n",
              "      <td>0.048171</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.574707</td>\n",
              "      <td>-0.354004</td>\n",
              "      <td>-0.511230</td>\n",
              "      <td>-0.302979</td>\n",
              "      <td>-0.427734</td>\n",
              "      <td>-0.218628</td>\n",
              "      <td>-0.197021</td>\n",
              "      <td>-0.052368</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7162</th>\n",
              "      <td>-1.408180</td>\n",
              "      <td>-0.493603</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.751953</td>\n",
              "      <td>-0.255859</td>\n",
              "      <td>-1.231445</td>\n",
              "      <td>-1.173828</td>\n",
              "      <td>-0.592773</td>\n",
              "      <td>-0.391602</td>\n",
              "      <td>-0.518066</td>\n",
              "      <td>-0.248413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7163</th>\n",
              "      <td>-0.393310</td>\n",
              "      <td>0.627128</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.258301</td>\n",
              "      <td>0.458008</td>\n",
              "      <td>0.062286</td>\n",
              "      <td>0.427246</td>\n",
              "      <td>-0.195557</td>\n",
              "      <td>0.263184</td>\n",
              "      <td>-0.023483</td>\n",
              "      <td>0.413086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7164</th>\n",
              "      <td>1.771596</td>\n",
              "      <td>0.547742</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.915527</td>\n",
              "      <td>0.829590</td>\n",
              "      <td>0.728027</td>\n",
              "      <td>0.502441</td>\n",
              "      <td>0.919922</td>\n",
              "      <td>0.443359</td>\n",
              "      <td>0.835449</td>\n",
              "      <td>0.739258</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7165 rows Ã— 11 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-23dc0c67-4fa6-4f83-9071-37ff990ede89')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-23dc0c67-4fa6-4f83-9071-37ff990ede89 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-23dc0c67-4fa6-4f83-9071-37ff990ede89');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-be050f32-f3df-4b65-a329-90209d42ac49\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-be050f32-f3df-4b65-a329-90209d42ac49')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-be050f32-f3df-4b65-a329-90209d42ac49 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Regular Ensemble"
      ],
      "metadata": {
        "id": "OYzCK0vbROz9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drop_columns = ['content','wording','fold']\n",
        "rmses = []\n",
        "\n",
        "for target in ['content','wording']:\n",
        "    preds = []\n",
        "    trues = []\n",
        "\n",
        "    for fold in range(4):\n",
        "        X_eval_cv = all_preds[all_preds[\"fold\"] == fold].drop(columns=drop_columns)\n",
        "        y_eval_cv = all_preds[all_preds[\"fold\"] == fold][target]\n",
        "        X_eval_cv = X_eval_cv.filter(regex=(f'_{target}'))\n",
        "        pred = X_eval_cv.apply(np.mean,axis=1)\n",
        "\n",
        "        trues.extend(y_eval_cv)\n",
        "        preds.extend(pred)\n",
        "\n",
        "\n",
        "    rmse = np.sqrt(mean_squared_error(trues, preds))\n",
        "    print(f\"{target}_rmse : {rmse}\")\n",
        "    rmses = rmses + [rmse]\n",
        "\n",
        "print(f\"mcrmse : {sum(rmses) / len(rmses)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2rCxYm7lmYP",
        "outputId": "9e7fa609-e310-477c-e93b-d24c8f71625a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content_rmse : 0.45367627071428196\n",
            "wording_rmse : 0.6334629437465463\n",
            "mcrmse : 0.5435696072304141\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Regular with LGBM"
      ],
      "metadata": {
        "id": "sel41flchXKh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "targets = [\"content\", \"wording\"]\n",
        "\n",
        "drop_columns = [\"fold\", \"student_id\", \"prompt_id\", \"text\",\n",
        "                \"prompt_question\", \"prompt_title\",\n",
        "                \"prompt_text\",\"prompt_length\",\n",
        "                \"avg_word_length\",\"semicolon_count\",\"neg\",\"neu\",\"pos\",\"compound\",\n",
        "                \"exclamation_count\",\"question_count\",\"punctuation_sum\",\"neg_prompt\",\"neu_prompt\",\"pos_prompt\",\n",
        "                \"compound_prompt\",\"flesch_reading_ease\",\"flesch_kincaid_grade\",\"gunning_fog\",\"automated_readability_index\",\n",
        "                \"coleman_liau_index\",\"linsear_write_formula\",\"dale_chall_readability_score\",\"text_standard\",\"spache_readability\",\n",
        "                \"mcalpine_eflaw\",\n",
        "               ] + targets\n",
        "\n",
        "\n",
        "model_dict = {}\n",
        "\n",
        "for target in targets:\n",
        "    models = []\n",
        "\n",
        "    for fold in range(4):\n",
        "\n",
        "        X_train_cv = train[train[\"fold\"] != fold].drop(columns=drop_columns)\n",
        "        y_train_cv = train[train[\"fold\"] != fold][target]\n",
        "\n",
        "        mean_pred = all_preds[all_preds['fold']!=fold].drop(columns=['content','wording','fold'])\n",
        "        mean_pred = mean_pred.filter(regex=(f'_content'))\n",
        "        mean_pred = mean_pred.apply(np.mean,axis=1)\n",
        "        X_train_cv['mean_pred_content'] = mean_pred\n",
        "\n",
        "        mean_pred = all_preds[all_preds['fold']!=fold].drop(columns=['content','wording','fold'])\n",
        "        mean_pred = mean_pred.filter(regex=(f'_wording'))\n",
        "        mean_pred = mean_pred.apply(np.mean,axis=1)\n",
        "        X_train_cv['mean_pred_wording'] = mean_pred\n",
        "\n",
        "        X_eval_cv = train[train[\"fold\"] == fold].drop(columns=drop_columns)\n",
        "        y_eval_cv = train[train[\"fold\"] == fold][target]\n",
        "\n",
        "        mean_pred = all_preds[all_preds['fold']==fold].drop(columns=['content','wording','fold'])\n",
        "        mean_pred = mean_pred.filter(regex=(f'_content'))\n",
        "        mean_pred = mean_pred.apply(np.mean,axis=1)\n",
        "        X_eval_cv['mean_pred_content'] = mean_pred\n",
        "\n",
        "        mean_pred = all_preds[all_preds['fold']==fold].drop(columns=['content','wording','fold'])\n",
        "        mean_pred = mean_pred.filter(regex=(f'_wording'))\n",
        "        mean_pred = mean_pred.apply(np.mean,axis=1)\n",
        "        X_eval_cv['mean_pred_wording'] = mean_pred\n",
        "\n",
        "\n",
        "        dtrain = lgb.Dataset(X_train_cv, label=y_train_cv)\n",
        "        dval = lgb.Dataset(X_eval_cv, label=y_eval_cv)\n",
        "\n",
        "        params = {\n",
        "                  'boosting_type': 'gbdt',\n",
        "                  'random_state': 42,\n",
        "                  'objective': 'regression',\n",
        "                  'metric': 'rmse',\n",
        "                  'learning_rate': 0.048,\n",
        "                  'lambda_l1': 0.0,\n",
        "                  'lambda_l2': 0.011\n",
        "                  }\n",
        "\n",
        "        evaluation_results = {}\n",
        "        model = lgb.train(params,\n",
        "                          num_boost_round=10000,\n",
        "                            #categorical_feature = categorical_features,\n",
        "                          valid_names=['train', 'valid'],\n",
        "                          train_set=dtrain,\n",
        "                          valid_sets=dval,\n",
        "                          callbacks=[\n",
        "                              lgb.early_stopping(stopping_rounds=30, verbose=False),\n",
        "                            #    lgb.log_evaluation(100),\n",
        "                            #   lgb.callback.record_evaluation(evaluation_results)\n",
        "                            ],\n",
        "                          )\n",
        "        models.append(model)\n",
        "\n",
        "    model_dict[target] = models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAfLPB8uaJV5",
        "outputId": "332b5895-e844-417a-a4a4-5c9bf4dc1fda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001317 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3004\n",
            "[LightGBM] [Info] Number of data points in the train set: 5108, number of used features: 21\n",
            "[LightGBM] [Info] Start training from score 0.017606\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001312 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2926\n",
            "[LightGBM] [Info] Number of data points in the train set: 5156, number of used features: 21\n",
            "[LightGBM] [Info] Start training from score -0.039959\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.158427 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2927\n",
            "[LightGBM] [Info] Number of data points in the train set: 5169, number of used features: 21\n",
            "[LightGBM] [Info] Start training from score 0.013356\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001746 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3022\n",
            "[LightGBM] [Info] Number of data points in the train set: 6062, number of used features: 21\n",
            "[LightGBM] [Info] Start training from score -0.044904\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001308 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3004\n",
            "[LightGBM] [Info] Number of data points in the train set: 5108, number of used features: 21\n",
            "[LightGBM] [Info] Start training from score -0.031791\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001345 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2926\n",
            "[LightGBM] [Info] Number of data points in the train set: 5156, number of used features: 21\n",
            "[LightGBM] [Info] Start training from score -0.060941\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001323 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2927\n",
            "[LightGBM] [Info] Number of data points in the train set: 5169, number of used features: 21\n",
            "[LightGBM] [Info] Start training from score 0.028040\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001483 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3022\n",
            "[LightGBM] [Info] Number of data points in the train set: 6062, number of used features: 21\n",
            "[LightGBM] [Info] Start training from score -0.168933\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cv\n",
        "rmses = []\n",
        "\n",
        "for target in targets:\n",
        "    models = model_dict[target]\n",
        "\n",
        "    preds = []\n",
        "    trues = []\n",
        "\n",
        "    for fold, model in enumerate(models):\n",
        "\n",
        "        X_eval_cv = train[train[\"fold\"] == fold].drop(columns=drop_columns)\n",
        "        y_eval_cv = train[train[\"fold\"] == fold][target]\n",
        "\n",
        "        mean_pred = all_preds[all_preds['fold']==fold].drop(columns=['content','wording','fold'])\n",
        "        mean_pred = mean_pred.filter(regex=(f'_content'))\n",
        "        mean_pred = mean_pred.apply(np.mean,axis=1)\n",
        "        X_eval_cv['mean_pred_content'] = mean_pred\n",
        "\n",
        "        mean_pred = all_preds[all_preds['fold']==fold].drop(columns=['content','wording','fold'])\n",
        "        mean_pred = mean_pred.filter(regex=(f'_wording'))\n",
        "        mean_pred = mean_pred.apply(np.mean,axis=1)\n",
        "        X_eval_cv['mean_pred_wording'] = mean_pred\n",
        "\n",
        "\n",
        "        pred = model.predict(X_eval_cv)\n",
        "\n",
        "        trues.extend(y_eval_cv)\n",
        "        preds.extend(pred)\n",
        "\n",
        "    rmse = np.sqrt(mean_squared_error(trues, preds))\n",
        "    print(f\"{target}_rmse : {rmse}\")\n",
        "    rmses = rmses + [rmse]\n",
        "\n",
        "print(f\"mcrmse : {sum(rmses) / len(rmses)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uA4ZfjYmduVU",
        "outputId": "5db847fb-43b3-4a04-8e42-dd04cba71c30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content_rmse : 0.4316029469934855\n",
            "wording_rmse : 0.5660460604544022\n",
            "mcrmse : 0.4988245037239438\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Bayesian Optimization"
      ],
      "metadata": {
        "id": "dhazgI2BN2vb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pbounds = {\n",
        "   'w0': (0.01, 0.99),\n",
        "   'w1': (0.01, 0.99),\n",
        "   'w2': (0.01, 0.99),\n",
        "   'w3': (0.01, 0.99),\n",
        "   'w4': (0.01, 0.99),\n",
        "   'w5': (0.01, 0.99),\n",
        "   'w6': (0.01, 0.99),\n",
        "}\n",
        "\n",
        "content_pred = all_preds.filter(regex=(f'_content'))\n",
        "pred_0 = content_pred[content_pred.columns[0]]\n",
        "pred_1 = content_pred[content_pred.columns[1]]\n",
        "pred_2 = content_pred[content_pred.columns[2]]\n",
        "pred_3 = content_pred[content_pred.columns[3]]\n",
        "pred_4 = content_pred[content_pred.columns[4]]\n",
        "pred_5 = content_pred[content_pred.columns[5]]\n",
        "pred_6 = content_pred[content_pred.columns[6]]\n",
        "y_actual = all_preds['content']\n",
        "\n",
        "def objective(w0, w1, w2, w3, w4, w5, w6):\n",
        "   weighted_avg_pred_logits = [w0*x + w1*y + w2*z + w3*t + w4*a +w5*b +w6*c for x, y, z, t,a,b,c in zip(pred_0, pred_1, pred_2, pred_3, pred_4, pred_5, pred_6)]\n",
        "#    weighted_avg_pred = np.argmax(weighted_avg_pred_logits, axis=1)\n",
        "   return 1-mean_squared_error(y_actual,weighted_avg_pred_logits,squared=False)"
      ],
      "metadata": {
        "id": "xazZoBBtN8FD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = BayesianOptimization(\n",
        "   f=objective,\n",
        "   pbounds=pbounds,\n",
        "   verbose=2,\n",
        "   random_state=42,\n",
        "   allow_duplicate_points=True\n",
        ")"
      ],
      "metadata": {
        "id": "ekMJ7-JHJmVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Nelder-Mead"
      ],
      "metadata": {
        "id": "XDl4ov8HoQQA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from numpy.random import rand\n",
        "from scipy.optimize import minimize"
      ],
      "metadata": {
        "id": "BWRnMT3YoSyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drop_columns = ['content','wording','fold']\n",
        "rmses = []\n",
        "\n",
        "for target in ['content','wording']:\n",
        "    preds = []\n",
        "    trues = []\n",
        "\n",
        "    for fold in range(4):\n",
        "        X_eval_cv = all_preds[all_preds[\"fold\"] == fold].drop(columns=drop_columns)\n",
        "        y_eval_cv = all_preds[all_preds[\"fold\"] == fold][target]\n",
        "        X_eval_cv = X_eval_cv.filter(regex=(f'_{target}'))\n",
        "\n",
        "        pred_0 = X_eval_cv[X_eval_cv.columns[0]]\n",
        "        pred_1 = X_eval_cv[X_eval_cv.columns[1]]\n",
        "        pred_2 = X_eval_cv[X_eval_cv.columns[2]]\n",
        "        pred_3 = X_eval_cv[X_eval_cv.columns[3]]\n",
        "        pred_4 = X_eval_cv[X_eval_cv.columns[4]]\n",
        "        # pred_5 = X_eval_cv[X_eval_cv.columns[5]]\n",
        "        # pred_6 = X_eval_cv[X_eval_cv.columns[6]]\n",
        "\n",
        "        def objective(x):\n",
        "            w0, w1, w2, w3, w4 = x\n",
        "            weighted_avg_pred_logits = [w0*x + w1*y + w2*z + w3*t + w4*a for x, y, z, t,a, in zip(pred_0, pred_1, pred_2, pred_3, pred_4)]\n",
        "            return mean_squared_error(y_eval_cv,weighted_avg_pred_logits,squared=False)\n",
        "\n",
        "\n",
        "        pt = rand(5)\n",
        "        result = minimize(objective, pt, method='nelder-mead')\n",
        "        solution = result['x']\n",
        "\n",
        "        for i,col in enumerate(X_eval_cv):\n",
        "            X_eval_cv[col] = X_eval_cv[col].multiply(solution[i])\n",
        "\n",
        "        pred = X_eval_cv.apply(np.sum,axis=1)\n",
        "        trues.extend(y_eval_cv)\n",
        "        preds.extend(pred)\n",
        "\n",
        "\n",
        "    rmse = np.sqrt(mean_squared_error(trues, preds))\n",
        "    print(f\"{target}_rmse : {rmse}\")\n",
        "    rmses = rmses + [rmse]\n",
        "\n",
        "print(f\"mcrmse : {sum(rmses) / len(rmses)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKKAFwbgS9aI",
        "outputId": "acf4bfaf-6849-4f64-b951-cceaaebcb17a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content_rmse : 0.4419184953066903\n",
            "wording_rmse : 0.5942609097578907\n",
            "mcrmse : 0.5180897025322905\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####LGBM+Nelder-mead"
      ],
      "metadata": {
        "id": "eFSyNvWuWeYS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "targets = [\"content\", \"wording\"]\n",
        "\n",
        "drop_columns = [\"fold\", \"student_id\", \"prompt_id\", \"text\",\n",
        "                \"prompt_question\", \"prompt_title\",\n",
        "                \"prompt_text\",\"prompt_length\",\n",
        "                \"avg_word_length\",\"semicolon_count\",\"neg\",\"neu\",\"pos\",\"compound\",\n",
        "                \"exclamation_count\",\"question_count\",\"punctuation_sum\",\"neg_prompt\",\"neu_prompt\",\"pos_prompt\",\n",
        "                \"compound_prompt\",\"flesch_reading_ease\",\"flesch_kincaid_grade\",\"gunning_fog\",\"automated_readability_index\",\n",
        "                \"coleman_liau_index\",\"linsear_write_formula\",\"dale_chall_readability_score\",\"text_standard\",\"spache_readability\",\n",
        "                \"mcalpine_eflaw\"\n",
        "               ] + targets\n",
        "\n",
        "model_dict = {}\n",
        "\n",
        "for target in targets:\n",
        "    models = []\n",
        "\n",
        "    for fold in range(4):\n",
        "\n",
        "        X_train_cv = train[train[\"fold\"] != fold].drop(columns=drop_columns)\n",
        "        y_train_cv = train[train[\"fold\"] != fold][target]\n",
        "\n",
        "        ####Content\n",
        "        mean_pred = all_preds[all_preds['fold']!=fold].drop(columns=['content','wording','fold'])\n",
        "        mean_pred = mean_pred.filter(regex=('_content'))\n",
        "\n",
        "        pred_0 = mean_pred[mean_pred.columns[0]]\n",
        "        pred_1 = mean_pred[mean_pred.columns[1]]\n",
        "        pred_2 = mean_pred[mean_pred.columns[2]]\n",
        "        pred_3 = mean_pred[mean_pred.columns[3]]\n",
        "        pred_4 = mean_pred[mean_pred.columns[4]]\n",
        "\n",
        "\n",
        "        def objective(x):\n",
        "            w0, w1, w2, w3, w4= x\n",
        "            weighted_avg_pred_logits = [w0*x + w1*y + w2*z + w3*t + w4*a for x, y, z, t,a in zip(pred_0, pred_1, pred_2, pred_3, pred_4)]\n",
        "            return mean_squared_error(y_train_cv,weighted_avg_pred_logits,squared=False)\n",
        "\n",
        "\n",
        "        pt = rand(5)\n",
        "        result = minimize(objective, pt, method='nelder-mead')\n",
        "        solution = result['x']\n",
        "\n",
        "        for i,col in enumerate(mean_pred):\n",
        "            mean_pred[col] = mean_pred[col].multiply(solution[i])\n",
        "\n",
        "        X_train_cv[f'nelder_mead_pred_content'] =  mean_pred.apply(np.sum,axis=1)\n",
        "\n",
        "        X_eval_cv = train[train[\"fold\"] == fold].drop(columns=drop_columns)\n",
        "        y_eval_cv = train[train[\"fold\"] == fold][target]\n",
        "\n",
        "        mean_pred = all_preds[all_preds['fold']==fold].drop(columns=['content','wording','fold'])\n",
        "        mean_pred = mean_pred.filter(regex=(f'_content'))\n",
        "\n",
        "        for i,col in enumerate(mean_pred):\n",
        "            mean_pred[col] = mean_pred[col].multiply(solution[i])\n",
        "\n",
        "        X_eval_cv[f'nelder_mead_pred_content'] =  mean_pred.apply(np.sum,axis=1)\n",
        "\n",
        "\n",
        "        ##################################################################\n",
        "        #### Wording\n",
        "\n",
        "        mean_pred = all_preds[all_preds['fold']!=fold].drop(columns=['content','wording','fold'])\n",
        "        mean_pred = mean_pred.filter(regex=('_wording'))\n",
        "\n",
        "        pred_0 = mean_pred[mean_pred.columns[0]]\n",
        "        pred_1 = mean_pred[mean_pred.columns[1]]\n",
        "        pred_2 = mean_pred[mean_pred.columns[2]]\n",
        "        pred_3 = mean_pred[mean_pred.columns[3]]\n",
        "        pred_4 = mean_pred[mean_pred.columns[4]]\n",
        "\n",
        "        def objective(x):\n",
        "            w0, w1, w2, w3, w4 = x\n",
        "            weighted_avg_pred_logits = [w0*x + w1*y + w2*z + w3*t + w4*a for x, y, z, t,a in zip(pred_0, pred_1, pred_2, pred_3, pred_4)]\n",
        "            return mean_squared_error(y_train_cv,weighted_avg_pred_logits,squared=False)\n",
        "\n",
        "\n",
        "        pt = rand(5)\n",
        "        result = minimize(objective, pt, method='nelder-mead')\n",
        "        solution = result['x']\n",
        "\n",
        "        for i,col in enumerate(mean_pred):\n",
        "            mean_pred[col] = mean_pred[col].multiply(solution[i])\n",
        "\n",
        "        X_train_cv[f'nelder_mead_pred_wording'] =  mean_pred.apply(np.sum,axis=1)\n",
        "\n",
        "        # X_eval_cv = train[train[\"fold\"] == fold].drop(columns=drop_columns)\n",
        "        # y_eval_cv = train[train[\"fold\"] == fold][target]\n",
        "\n",
        "        mean_pred = all_preds[all_preds['fold']==fold].drop(columns=['content','wording','fold'])\n",
        "        mean_pred = mean_pred.filter(regex=(f'_wording'))\n",
        "\n",
        "        for i,col in enumerate(mean_pred):\n",
        "            mean_pred[col] = mean_pred[col].multiply(solution[i])\n",
        "\n",
        "        X_eval_cv[f'nelder_mead_pred_wording'] =  mean_pred.apply(np.sum,axis=1)\n",
        "\n",
        "\n",
        "\n",
        "        dtrain = lgb.Dataset(X_train_cv, label=y_train_cv)\n",
        "        dval = lgb.Dataset(X_eval_cv, label=y_eval_cv)\n",
        "\n",
        "        params = {\n",
        "                  'boosting_type': 'gbdt',\n",
        "                  'random_state': 42,\n",
        "                  'objective': 'regression',\n",
        "                  'metric': 'rmse',\n",
        "                  'learning_rate': 0.048,\n",
        "                  'lambda_l1': 0.0,\n",
        "                  'lambda_l2': 0.011\n",
        "                  }\n",
        "\n",
        "        evaluation_results = {}\n",
        "        model = lgb.train(params,\n",
        "                          num_boost_round=10000,\n",
        "                            #categorical_feature = categorical_features,\n",
        "                          valid_names=['train', 'valid'],\n",
        "                          train_set=dtrain,\n",
        "                          valid_sets=dval,\n",
        "                          callbacks=[\n",
        "                              lgb.early_stopping(stopping_rounds=30, verbose=True),\n",
        "                               lgb.log_evaluation(100),\n",
        "                              lgb.callback.record_evaluation(evaluation_results)\n",
        "                            ],\n",
        "                          )\n",
        "        models.append(model)\n",
        "\n",
        "    model_dict[target] = models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wU54JeLBW2Gl",
        "outputId": "28f0696f-e880-43d1-a300-fbf0029ec567"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001274 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3004\n",
            "[LightGBM] [Info] Number of data points in the train set: 5108, number of used features: 21\n",
            "[LightGBM] [Info] Start training from score 0.017606\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "Early stopping, best iteration is:\n",
            "[59]\ttrain's rmse: 0.396699\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001281 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2926\n",
            "[LightGBM] [Info] Number of data points in the train set: 5156, number of used features: 21\n",
            "[LightGBM] [Info] Start training from score -0.039959\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[100]\ttrain's rmse: 0.470891\n",
            "Early stopping, best iteration is:\n",
            "[126]\ttrain's rmse: 0.4705\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001528 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2927\n",
            "[LightGBM] [Info] Number of data points in the train set: 5169, number of used features: 21\n",
            "[LightGBM] [Info] Start training from score 0.013356\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[100]\ttrain's rmse: 0.416544\n",
            "Early stopping, best iteration is:\n",
            "[76]\ttrain's rmse: 0.416409\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000745 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3022\n",
            "[LightGBM] [Info] Number of data points in the train set: 6062, number of used features: 21\n",
            "[LightGBM] [Info] Start training from score -0.044904\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[100]\ttrain's rmse: 0.452851\n",
            "Early stopping, best iteration is:\n",
            "[107]\ttrain's rmse: 0.452297\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001312 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3004\n",
            "[LightGBM] [Info] Number of data points in the train set: 5108, number of used features: 21\n",
            "[LightGBM] [Info] Start training from score -0.031791\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "Early stopping, best iteration is:\n",
            "[58]\ttrain's rmse: 0.535018\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002815 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2926\n",
            "[LightGBM] [Info] Number of data points in the train set: 5156, number of used features: 21\n",
            "[LightGBM] [Info] Start training from score -0.060941\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "Early stopping, best iteration is:\n",
            "[27]\ttrain's rmse: 0.668694\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001273 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2927\n",
            "[LightGBM] [Info] Number of data points in the train set: 5169, number of used features: 21\n",
            "[LightGBM] [Info] Start training from score 0.028040\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[100]\ttrain's rmse: 0.494106\n",
            "Early stopping, best iteration is:\n",
            "[74]\ttrain's rmse: 0.493119\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001536 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3022\n",
            "[LightGBM] [Info] Number of data points in the train set: 6062, number of used features: 21\n",
            "[LightGBM] [Info] Start training from score -0.168933\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[100]\ttrain's rmse: 0.646919\n",
            "Early stopping, best iteration is:\n",
            "[135]\ttrain's rmse: 0.644031\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cv\n",
        "rmses = []\n",
        "\n",
        "for target in targets:\n",
        "    models = model_dict[target]\n",
        "\n",
        "    preds = []\n",
        "    trues = []\n",
        "\n",
        "    for fold, model in enumerate(models):\n",
        "\n",
        "        X_eval_cv = train[train[\"fold\"] == fold].drop(columns=drop_columns)\n",
        "        y_eval_cv = train[train[\"fold\"] == fold][target]\n",
        "\n",
        "        #### Content\n",
        "        mean_pred = all_preds[all_preds['fold']!=fold].drop(columns=['content','wording','fold'])\n",
        "        mean_pred = mean_pred.filter(regex=(f'_content'))\n",
        "\n",
        "        pred_0 = mean_pred[mean_pred.columns[0]]\n",
        "        pred_1 = mean_pred[mean_pred.columns[1]]\n",
        "        pred_2 = mean_pred[mean_pred.columns[2]]\n",
        "        pred_3 = mean_pred[mean_pred.columns[3]]\n",
        "        pred_4 = mean_pred[mean_pred.columns[4]]\n",
        "\n",
        "\n",
        "        def objective(x):\n",
        "            w0, w1, w2, w3, w4 = x\n",
        "            weighted_avg_pred_logits = [w0*x + w1*y + w2*z + w3*t + w4*a  for x, y, z, t,a in zip(pred_0, pred_1, pred_2, pred_3, pred_4)]\n",
        "            return mean_squared_error(all_preds[all_preds['fold']!=fold][target],weighted_avg_pred_logits,squared=False)\n",
        "\n",
        "        pt = rand(5)\n",
        "        result = minimize(objective, pt, method='nelder-mead')\n",
        "        solution = result['x']\n",
        "\n",
        "        mean_pred = all_preds[all_preds['fold']==fold].drop(columns=['content','wording','fold'])\n",
        "        mean_pred = mean_pred.filter(regex=(f'_content'))\n",
        "        for i,col in enumerate(mean_pred):\n",
        "            mean_pred[col] = mean_pred[col].multiply(solution[i])\n",
        "\n",
        "        X_eval_cv['nelder_mead_pred_content'] =  mean_pred.apply(np.sum,axis=1)\n",
        "\n",
        "\n",
        "        ##################################################################\n",
        "        ####Wording\n",
        "\n",
        "        mean_pred = all_preds[all_preds['fold']!=fold].drop(columns=['content','wording','fold'])\n",
        "        mean_pred = mean_pred.filter(regex=(f'_wording'))\n",
        "\n",
        "        pred_0 = mean_pred[mean_pred.columns[0]]\n",
        "        pred_1 = mean_pred[mean_pred.columns[1]]\n",
        "        pred_2 = mean_pred[mean_pred.columns[2]]\n",
        "        pred_3 = mean_pred[mean_pred.columns[3]]\n",
        "        pred_4 = mean_pred[mean_pred.columns[4]]\n",
        "\n",
        "        def objective(x):\n",
        "            w0, w1, w2, w3, w4 = x\n",
        "            weighted_avg_pred_logits = [w0*x + w1*y + w2*z + w3*t + w4*a  for x, y, z, t,a in zip(pred_0, pred_1, pred_2, pred_3, pred_4)]\n",
        "            return mean_squared_error(all_preds[all_preds['fold']!=fold][target],weighted_avg_pred_logits,squared=False)\n",
        "\n",
        "        pt = rand(5)\n",
        "        result = minimize(objective, pt, method='nelder-mead')\n",
        "        solution = result['x']\n",
        "\n",
        "        mean_pred = all_preds[all_preds['fold']==fold].drop(columns=['content','wording','fold'])\n",
        "        mean_pred = mean_pred.filter(regex=(f'_wording'))\n",
        "        for i,col in enumerate(mean_pred):\n",
        "            mean_pred[col] = mean_pred[col].multiply(solution[i])\n",
        "\n",
        "        X_eval_cv['nelder_mead_pred_wording'] =  mean_pred.apply(np.sum,axis=1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        pred = model.predict(X_eval_cv)\n",
        "\n",
        "        trues.extend(y_eval_cv)\n",
        "        preds.extend(pred)\n",
        "\n",
        "    rmse = np.sqrt(mean_squared_error(trues, preds))\n",
        "    print(f\"{target}_rmse : {rmse}\")\n",
        "    rmses = rmses + [rmse]\n",
        "\n",
        "print(f\"mcrmse : {sum(rmses) / len(rmses)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bC6cXHaSZBGW",
        "outputId": "7a5838af-1268-45ba-e3ea-6624b0ee9a37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content_rmse : 0.4324876736391451\n",
            "wording_rmse : 0.5824039631737561\n",
            "mcrmse : 0.5074458184064505\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Dual Annealing"
      ],
      "metadata": {
        "id": "zLGJgcj9Au9q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.optimize import dual_annealing"
      ],
      "metadata": {
        "id": "ayHIVpzcAxr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drop_columns = ['content','wording','fold']\n",
        "rmses = []\n",
        "\n",
        "for target in ['content','wording']:\n",
        "    preds = []\n",
        "    trues = []\n",
        "\n",
        "    for fold in range(4):\n",
        "        X_eval_cv = all_preds[all_preds[\"fold\"] == fold].drop(columns=drop_columns)\n",
        "        y_eval_cv = all_preds[all_preds[\"fold\"] == fold][target]\n",
        "        X_eval_cv = X_eval_cv.filter(regex=(f'_{target}'))\n",
        "\n",
        "        pred_0 = X_eval_cv[X_eval_cv.columns[0]]\n",
        "        pred_1 = X_eval_cv[X_eval_cv.columns[1]]\n",
        "        pred_2 = X_eval_cv[X_eval_cv.columns[2]]\n",
        "        pred_3 = X_eval_cv[X_eval_cv.columns[3]]\n",
        "        pred_4 = X_eval_cv[X_eval_cv.columns[4]]\n",
        "        pred_5 = X_eval_cv[X_eval_cv.columns[5]]\n",
        "        pred_6 = X_eval_cv[X_eval_cv.columns[6]]\n",
        "\n",
        "        def objective(x):\n",
        "            w0, w1, w2, w3, w4, w5, w6 = x\n",
        "            weighted_avg_pred_logits = [w0*x + w1*y + w2*z + w3*t + w4*a +w5*b +w6*c for x, y, z, t,a,b,c in zip(pred_0, pred_1, pred_2, pred_3, pred_4, pred_5, pred_6)]\n",
        "            return mean_squared_error(y_eval_cv,weighted_avg_pred_logits,squared=False)\n",
        "\n",
        "\n",
        "        r_min, r_max = 0, 1\n",
        "        bounds = np.array([[r_min, r_max], [r_min, r_max], [r_min, r_max], [r_min, r_max],[r_min, r_max],[r_min, r_max],[r_min, r_max]])\n",
        "        result = dual_annealing(objective, bounds)\n",
        "        solution = result['x']\n",
        "\n",
        "        for i,col in enumerate(X_eval_cv):\n",
        "            X_eval_cv[col] = X_eval_cv[col].multiply(solution[i])\n",
        "\n",
        "        pred = X_eval_cv.apply(np.sum,axis=1)\n",
        "        trues.extend(y_eval_cv)\n",
        "        preds.extend(pred)\n",
        "\n",
        "\n",
        "    rmse = np.sqrt(mean_squared_error(trues, preds))\n",
        "    print(f\"{target}_rmse : {rmse}\")\n",
        "    rmses = rmses + [rmse]\n",
        "\n",
        "print(f\"mcrmse : {sum(rmses) / len(rmses)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "gUrE5xfOAzmH",
        "outputId": "95e6ce49-0cae-4bc8-fecd-a2b27664dddb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-106-091efbe5009f>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_eval_cv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mX_eval_cv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_eval_cv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolution\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_eval_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 7 is out of bounds for axis 0 with size 7"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Ridge Ensmeble"
      ],
      "metadata": {
        "id": "4HQcO8GwRK7n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drop_columns = ['content','wording','fold']\n",
        "rmses = []\n",
        "\n",
        "for target in ['content','wording']:\n",
        "    preds = []\n",
        "    trues = []\n",
        "\n",
        "    for fold in range(4):\n",
        "        ridge_train_cv = all_preds[all_preds[\"fold\"] != fold].drop(columns=drop_columns)\n",
        "        ridge_y_cv = all_preds[all_preds[\"fold\"] != fold][target]\n",
        "        ridge_train_cv = ridge_train_cv.filter(regex=(f'_{target}'))\n",
        "\n",
        "        X_eval_cv = all_preds[all_preds[\"fold\"] == fold].drop(columns=drop_columns)\n",
        "        y_eval_cv = all_preds[all_preds[\"fold\"] == fold][target]\n",
        "        X_eval_cv = X_eval_cv.filter(regex=(f'_{target}'))\n",
        "\n",
        "        ridge = Ridge(random_state=42)\n",
        "        ridge.fit(ridge_train_cv,ridge_y_cv)\n",
        "\n",
        "        for i,col in enumerate(X_eval_cv):\n",
        "            X_eval_cv[col] = X_eval_cv[col].multiply(ridge.coef_[i])\n",
        "\n",
        "        pred = X_eval_cv.apply(np.sum,axis=1)\n",
        "\n",
        "        trues.extend(y_eval_cv)\n",
        "        preds.extend(pred)\n",
        "\n",
        "\n",
        "    rmse = np.sqrt(mean_squared_error(trues, preds))\n",
        "    print(f\"{target}_rmse : {rmse}\")\n",
        "    rmses = rmses + [rmse]\n",
        "\n",
        "print(f\"mcrmse : {sum(rmses) / len(rmses)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDtsySFXoiOw",
        "outputId": "6c71f8bc-a3c7-410c-e1ab-3f13e124e523"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content_rmse : 0.46072068009387385\n",
            "wording_rmse : 0.6428043430655724\n",
            "mcrmse : 0.5517625115797231\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####LGBM"
      ],
      "metadata": {
        "id": "cMreWBgVnrby"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "targets = [\"content\", \"wording\"]\n",
        "\n",
        "drop_columns = [\"fold\", \"student_id\", \"prompt_id\", \"text\",\n",
        "                \"prompt_question\", \"prompt_title\",\n",
        "                \"prompt_text\",\"prompt_length\",\n",
        "                \"avg_word_length\",\"semicolon_count\",\"neg\",\"neu\",\"pos\",\"compound\",\n",
        "                \"exclamation_count\",\"question_count\",\"punctuation_sum\",\"neg_prompt\",\"neu_prompt\",\"pos_prompt\",\n",
        "                \"compound_prompt\",\"flesch_reading_ease\",\"flesch_kincaid_grade\",\"gunning_fog\",\"automated_readability_index\",\n",
        "                \"coleman_liau_index\",\"linsear_write_formula\",\"dale_chall_readability_score\",\"text_standard\",\"spache_readability\",\n",
        "                \"mcalpine_eflaw\"\n",
        "               ] + targets\n",
        "\n",
        "\n",
        "model_dict = {}\n",
        "\n",
        "for target in targets:\n",
        "    models = []\n",
        "\n",
        "    for fold in range(4):\n",
        "\n",
        "        X_train_cv = train[train[\"fold\"] != fold].drop(columns=drop_columns)\n",
        "        y_train_cv = train[train[\"fold\"] != fold][target]\n",
        "\n",
        "        mean_pred = all_preds[all_preds['fold']!=fold].drop(columns=['content','wording','fold'])\n",
        "        mean_pred = mean_pred.filter(regex=(f'_{target}'))\n",
        "\n",
        "        ridge = Ridge(random_state=42)\n",
        "        ridge.fit(mean_pred,all_preds[all_preds['fold']!=fold][target])\n",
        "\n",
        "        for i,col in enumerate(mean_pred):\n",
        "            mean_pred[col] = mean_pred[col].multiply(ridge.coef_[i])\n",
        "\n",
        "        X_train_cv['ridge_pred'] =  mean_pred.apply(np.sum,axis=1)\n",
        "\n",
        "        X_eval_cv = train[train[\"fold\"] == fold].drop(columns=drop_columns)\n",
        "        y_eval_cv = train[train[\"fold\"] == fold][target]\n",
        "\n",
        "        mean_pred = all_preds[all_preds['fold']==fold].drop(columns=['content','wording','fold'])\n",
        "        mean_pred = mean_pred.filter(regex=(f'_{target}'))\n",
        "\n",
        "        for i,col in enumerate(mean_pred):\n",
        "            mean_pred[col] = mean_pred[col].multiply(ridge.coef_[i])\n",
        "\n",
        "        X_eval_cv['ridge_pred'] =  mean_pred.apply(np.sum,axis=1)\n",
        "\n",
        "\n",
        "        dtrain = lgb.Dataset(X_train_cv, label=y_train_cv)\n",
        "        dval = lgb.Dataset(X_eval_cv, label=y_eval_cv)\n",
        "\n",
        "        params = {\n",
        "                  'boosting_type': 'gbdt',\n",
        "                  'random_state': 42,\n",
        "                  'objective': 'regression',\n",
        "                  'metric': 'rmse',\n",
        "                  'learning_rate': 0.048,\n",
        "                  'lambda_l1': 0.0,\n",
        "                  'lambda_l2': 0.011\n",
        "                  }\n",
        "\n",
        "        evaluation_results = {}\n",
        "        model = lgb.train(params,\n",
        "                          num_boost_round=10000,\n",
        "                            #categorical_feature = categorical_features,\n",
        "                          valid_names=['train', 'valid'],\n",
        "                          train_set=dtrain,\n",
        "                          valid_sets=dval,\n",
        "                          callbacks=[\n",
        "                              lgb.early_stopping(stopping_rounds=30, verbose=True),\n",
        "                               lgb.log_evaluation(100),\n",
        "                              lgb.callback.record_evaluation(evaluation_results)\n",
        "                            ],\n",
        "                          )\n",
        "        models.append(model)\n",
        "\n",
        "    model_dict[target] = models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0JSlNY4hDWB",
        "outputId": "5b822982-93ce-41f8-d4c9-d86875eab03b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001037 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2749\n",
            "[LightGBM] [Info] Number of data points in the train set: 5108, number of used features: 20\n",
            "[LightGBM] [Info] Start training from score 0.017606\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "Early stopping, best iteration is:\n",
            "[54]\ttrain's rmse: 0.39945\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001191 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2671\n",
            "[LightGBM] [Info] Number of data points in the train set: 5156, number of used features: 20\n",
            "[LightGBM] [Info] Start training from score -0.039959\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[100]\ttrain's rmse: 0.496807\n",
            "[200]\ttrain's rmse: 0.49598\n",
            "Early stopping, best iteration is:\n",
            "[175]\ttrain's rmse: 0.494856\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001182 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2672\n",
            "[LightGBM] [Info] Number of data points in the train set: 5169, number of used features: 20\n",
            "[LightGBM] [Info] Start training from score 0.013356\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "Early stopping, best iteration is:\n",
            "[64]\ttrain's rmse: 0.425954\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001374 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2767\n",
            "[LightGBM] [Info] Number of data points in the train set: 6062, number of used features: 20\n",
            "[LightGBM] [Info] Start training from score -0.044904\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[100]\ttrain's rmse: 0.443418\n",
            "Early stopping, best iteration is:\n",
            "[99]\ttrain's rmse: 0.44338\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001144 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2749\n",
            "[LightGBM] [Info] Number of data points in the train set: 5108, number of used features: 20\n",
            "[LightGBM] [Info] Start training from score -0.031791\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "Early stopping, best iteration is:\n",
            "[57]\ttrain's rmse: 0.521984\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.196924 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2671\n",
            "[LightGBM] [Info] Number of data points in the train set: 5156, number of used features: 20\n",
            "[LightGBM] [Info] Start training from score -0.060941\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "Early stopping, best iteration is:\n",
            "[63]\ttrain's rmse: 0.680368\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001186 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2672\n",
            "[LightGBM] [Info] Number of data points in the train set: 5169, number of used features: 20\n",
            "[LightGBM] [Info] Start training from score 0.028040\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[100]\ttrain's rmse: 0.499208\n",
            "Early stopping, best iteration is:\n",
            "[80]\ttrain's rmse: 0.498468\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.154162 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2767\n",
            "[LightGBM] [Info] Number of data points in the train set: 6062, number of used features: 20\n",
            "[LightGBM] [Info] Start training from score -0.168933\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[100]\ttrain's rmse: 0.606794\n",
            "Early stopping, best iteration is:\n",
            "[113]\ttrain's rmse: 0.606144\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cv\n",
        "rmses = []\n",
        "\n",
        "for target in targets:\n",
        "    models = model_dict[target]\n",
        "\n",
        "    preds = []\n",
        "    trues = []\n",
        "\n",
        "    for fold, model in enumerate(models):\n",
        "\n",
        "        X_eval_cv = train[train[\"fold\"] == fold].drop(columns=drop_columns)\n",
        "        y_eval_cv = train[train[\"fold\"] == fold][target]\n",
        "\n",
        "        mean_pred = all_preds[all_preds['fold']!=fold].drop(columns=['content','wording','fold'])\n",
        "        ridge = Ridge(random_state=42)\n",
        "        ridge.fit(mean_pred,all_preds[all_preds['fold']!=fold][target])\n",
        "\n",
        "        mean_pred= all_preds[all_preds['fold']==fold].drop(columns=['content','wording','fold'])\n",
        "\n",
        "        for i,col in enumerate(mean_pred):\n",
        "            mean_pred[col] = mean_pred[col].multiply(ridge.coef_[i])\n",
        "\n",
        "        X_eval_cv['ridge_pred'] =  mean_pred.apply(np.sum,axis=1)\n",
        "\n",
        "\n",
        "        pred = model.predict(X_eval_cv)\n",
        "\n",
        "        trues.extend(y_eval_cv)\n",
        "        preds.extend(pred)\n",
        "\n",
        "    rmse = np.sqrt(mean_squared_error(trues, preds))\n",
        "    print(f\"{target}_rmse : {rmse}\")\n",
        "    rmses = rmses + [rmse]\n",
        "\n",
        "print(f\"mcrmse : {sum(rmses) / len(rmses)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFunIm18nRIo",
        "outputId": "9ea82ce6-c495-4f80-9af2-6f0dc65d49af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content_rmse : 0.44540256880891765\n",
            "wording_rmse : 0.5894428054108428\n",
            "mcrmse : 0.5174226871098803\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###SVR"
      ],
      "metadata": {
        "id": "pMwLv6KAyuJ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline"
      ],
      "metadata": {
        "id": "Nw0bbveM1eWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drop_columns = ['content','wording','fold']\n",
        "rmses = []\n",
        "\n",
        "for target in ['content','wording']:\n",
        "    preds = []\n",
        "    trues = []\n",
        "\n",
        "    for fold in range(4):\n",
        "        ridge_train_cv = all_preds[all_preds[\"fold\"] != fold].drop(columns=drop_columns)\n",
        "        ridge_y_cv = all_preds[all_preds[\"fold\"] != fold][target]\n",
        "        ridge_train_cv = ridge_train_cv.filter(regex=(f'_{target}'))\n",
        "\n",
        "        X_eval_cv = all_preds[all_preds[\"fold\"] == fold].drop(columns=drop_columns)\n",
        "        y_eval_cv = all_preds[all_preds[\"fold\"] == fold][target]\n",
        "        X_eval_cv = X_eval_cv.filter(regex=(f'_{target}'))\n",
        "\n",
        "        ridge = make_pipeline(StandardScaler(), SVR(kernel='linear',C=1.0, epsilon=0.2))\n",
        "        ridge.fit(ridge_train_cv,ridge_y_cv)\n",
        "\n",
        "        for i,col in enumerate(X_eval_cv):\n",
        "            X_eval_cv[col] = X_eval_cv[col].multiply(ridge.named_steps['svr'].coef_[0][i])\n",
        "\n",
        "        pred = X_eval_cv.apply(np.sum,axis=1)\n",
        "\n",
        "        trues.extend(y_eval_cv)\n",
        "        preds.extend(pred)\n",
        "\n",
        "\n",
        "    rmse = np.sqrt(mean_squared_error(trues, preds))\n",
        "    print(f\"{target}_rmse : {rmse}\")\n",
        "    rmses = rmses + [rmse]\n",
        "\n",
        "print(f\"mcrmse : {sum(rmses) / len(rmses)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSOrsx_oywge",
        "outputId": "fa59fe9c-ae00-47a1-f633-a629919f4408"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content_rmse : 0.4657488214635456\n",
            "wording_rmse : 0.6467956025170459\n",
            "mcrmse : 0.5562722119902958\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "targets = [\"content\", \"wording\"]\n",
        "\n",
        "drop_columns = [\"fold\", \"student_id\", \"prompt_id\", \"text\",\n",
        "                \"prompt_question\", \"prompt_title\",\n",
        "                \"prompt_text\",\"prompt_length\",\n",
        "                \"avg_word_length\",\"semicolon_count\",\"neg\",\"neu\",\"pos\",\"compound\",\n",
        "                \"exclamation_count\",\"question_count\",\"punctuation_sum\",\"neg_prompt\",\"neu_prompt\",\"pos_prompt\",\n",
        "                \"compound_prompt\",\"flesch_reading_ease\",\"flesch_kincaid_grade\",\"gunning_fog\",\"automated_readability_index\",\n",
        "                \"coleman_liau_index\",\"linsear_write_formula\",\"dale_chall_readability_score\",\"text_standard\",\"spache_readability\",\n",
        "                \"mcalpine_eflaw\"\n",
        "               ] + targets\n",
        "\n",
        "\n",
        "model_dict = {}\n",
        "\n",
        "for target in targets:\n",
        "    models = []\n",
        "\n",
        "    for fold in range(4):\n",
        "\n",
        "        X_train_cv = train[train[\"fold\"] != fold].drop(columns=drop_columns)\n",
        "        y_train_cv = train[train[\"fold\"] != fold][target]\n",
        "\n",
        "        mean_pred = all_preds[all_preds['fold']!=fold].drop(columns=['content','wording','fold'])\n",
        "        mean_pred = mean_pred.filter(regex=(f'_{target}'))\n",
        "\n",
        "        ridge = make_pipeline(StandardScaler(), SVR(kernel='linear',C=1.0, epsilon=0.2))\n",
        "        ridge.fit(mean_pred,all_preds[all_preds['fold']!=fold][target])\n",
        "\n",
        "        for i,col in enumerate(mean_pred):\n",
        "            mean_pred[col] = mean_pred[col].multiply(ridge.named_steps['svr'].coef_[0][i])\n",
        "\n",
        "        X_train_cv['ridge_pred'] =  mean_pred.apply(np.sum,axis=1)\n",
        "        # mean_pred = all_preds[all_preds['fold']!=fold].drop(columns=['content','wording','fold'])\n",
        "        # mean_pred = mean_pred.filter(regex=(f'_wording'))\n",
        "        # mean_pred = mean_pred.apply(np.mean,axis=1)\n",
        "        # X_train_cv['mean_pred_wording'] = mean_pred\n",
        "\n",
        "        X_eval_cv = train[train[\"fold\"] == fold].drop(columns=drop_columns)\n",
        "        y_eval_cv = train[train[\"fold\"] == fold][target]\n",
        "\n",
        "        mean_pred = all_preds[all_preds['fold']==fold].drop(columns=['content','wording','fold'])\n",
        "        mean_pred = mean_pred.filter(regex=(f'_{target}'))\n",
        "\n",
        "        for i,col in enumerate(mean_pred):\n",
        "            mean_pred[col] = mean_pred[col].multiply(ridge.named_steps['svr'].coef_[0][i])\n",
        "\n",
        "        X_eval_cv['ridge_pred'] =  mean_pred.apply(np.sum,axis=1)\n",
        "\n",
        "        # mean_pred = all_preds[all_preds['fold']==fold].drop(columns=['content','wording','fold'])\n",
        "        # mean_pred = mean_pred.filter(regex=(f'_wording'))\n",
        "        # mean_pred = mean_pred.apply(np.mean,axis=1)\n",
        "        # X_eval_cv['mean_pred_wording'] = mean_pred\n",
        "\n",
        "\n",
        "        dtrain = lgb.Dataset(X_train_cv, label=y_train_cv)\n",
        "        dval = lgb.Dataset(X_eval_cv, label=y_eval_cv)\n",
        "\n",
        "        params = {\n",
        "                  'boosting_type': 'gbdt',\n",
        "                  'random_state': 42,\n",
        "                  'objective': 'regression',\n",
        "                  'metric': 'rmse',\n",
        "                  'learning_rate': 0.048,\n",
        "                  'lambda_l1': 0.0,\n",
        "                  'lambda_l2': 0.011\n",
        "                  }\n",
        "\n",
        "        evaluation_results = {}\n",
        "        model = lgb.train(params,\n",
        "                          num_boost_round=10000,\n",
        "                            #categorical_feature = categorical_features,\n",
        "                          valid_names=['train', 'valid'],\n",
        "                          train_set=dtrain,\n",
        "                          valid_sets=dval,\n",
        "                          callbacks=[\n",
        "                              lgb.early_stopping(stopping_rounds=30, verbose=True),\n",
        "                               lgb.log_evaluation(100),\n",
        "                              lgb.callback.record_evaluation(evaluation_results)\n",
        "                            ],\n",
        "                          )\n",
        "        models.append(model)\n",
        "\n",
        "    model_dict[target] = models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4nQWYCn5ZgD",
        "outputId": "151e2c2d-77ec-4273-e821-819a044954b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001284 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2749\n",
            "[LightGBM] [Info] Number of data points in the train set: 5108, number of used features: 20\n",
            "[LightGBM] [Info] Start training from score 0.017606\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "Early stopping, best iteration is:\n",
            "[65]\ttrain's rmse: 0.394069\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001300 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2671\n",
            "[LightGBM] [Info] Number of data points in the train set: 5156, number of used features: 20\n",
            "[LightGBM] [Info] Start training from score -0.039959\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[100]\ttrain's rmse: 0.493765\n",
            "Early stopping, best iteration is:\n",
            "[123]\ttrain's rmse: 0.49356\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001531 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2672\n",
            "[LightGBM] [Info] Number of data points in the train set: 5169, number of used features: 20\n",
            "[LightGBM] [Info] Start training from score 0.013356\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "Early stopping, best iteration is:\n",
            "[59]\ttrain's rmse: 0.429775\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001360 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2767\n",
            "[LightGBM] [Info] Number of data points in the train set: 6062, number of used features: 20\n",
            "[LightGBM] [Info] Start training from score -0.044904\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[100]\ttrain's rmse: 0.442622\n",
            "Early stopping, best iteration is:\n",
            "[105]\ttrain's rmse: 0.44238\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001229 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2749\n",
            "[LightGBM] [Info] Number of data points in the train set: 5108, number of used features: 20\n",
            "[LightGBM] [Info] Start training from score -0.031791\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "Early stopping, best iteration is:\n",
            "[55]\ttrain's rmse: 0.526243\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.179906 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2671\n",
            "[LightGBM] [Info] Number of data points in the train set: 5156, number of used features: 20\n",
            "[LightGBM] [Info] Start training from score -0.060941\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "Early stopping, best iteration is:\n",
            "[48]\ttrain's rmse: 0.675224\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.201907 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2672\n",
            "[LightGBM] [Info] Number of data points in the train set: 5169, number of used features: 20\n",
            "[LightGBM] [Info] Start training from score 0.028040\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[100]\ttrain's rmse: 0.50028\n",
            "Early stopping, best iteration is:\n",
            "[84]\ttrain's rmse: 0.499469\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001439 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2767\n",
            "[LightGBM] [Info] Number of data points in the train set: 6062, number of used features: 20\n",
            "[LightGBM] [Info] Start training from score -0.168933\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[100]\ttrain's rmse: 0.620452\n",
            "Early stopping, best iteration is:\n",
            "[94]\ttrain's rmse: 0.6199\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rmses = []\n",
        "\n",
        "for target in targets:\n",
        "    models = model_dict[target]\n",
        "\n",
        "    preds = []\n",
        "    trues = []\n",
        "\n",
        "    for fold, model in enumerate(models):\n",
        "\n",
        "        X_eval_cv = train[train[\"fold\"] == fold].drop(columns=drop_columns)\n",
        "        y_eval_cv = train[train[\"fold\"] == fold][target]\n",
        "\n",
        "        mean_pred = all_preds[all_preds['fold']!=fold].drop(columns=['content','wording','fold'])\n",
        "        ridge = make_pipeline(StandardScaler(), SVR(kernel='linear',C=1.0, epsilon=0.2))\n",
        "        ridge.fit(mean_pred,all_preds[all_preds['fold']!=fold][target])\n",
        "\n",
        "        mean_pred= all_preds[all_preds['fold']==fold].drop(columns=['content','wording','fold'])\n",
        "\n",
        "        for i,col in enumerate(mean_pred):\n",
        "            mean_pred[col] = mean_pred[col].multiply(ridge.named_steps['svr'].coef_[0][i])\n",
        "\n",
        "        X_eval_cv['ridge_pred'] =  mean_pred.apply(np.sum,axis=1)\n",
        "\n",
        "\n",
        "        pred = model.predict(X_eval_cv)\n",
        "\n",
        "        trues.extend(y_eval_cv)\n",
        "        preds.extend(pred)\n",
        "\n",
        "    rmse = np.sqrt(mean_squared_error(trues, preds))\n",
        "    print(f\"{target}_rmse : {rmse}\")\n",
        "    rmses = rmses + [rmse]\n",
        "\n",
        "print(f\"mcrmse : {sum(rmses) / len(rmses)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Box3kBcf5zFA",
        "outputId": "9f9de471-ef2c-4359-ad27-8f9271a30d09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content_rmse : 0.4421259267987118\n",
            "wording_rmse : 0.5955446103201631\n",
            "mcrmse : 0.5188352685594375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###LGMB - Predictions as Features"
      ],
      "metadata": {
        "id": "Mu48dItTrMD8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "targets = [\"content\", \"wording\"]\n",
        "\n",
        "drop_columns = [\"fold\", \"student_id\", \"prompt_id\", \"text\",\n",
        "                \"prompt_question\", \"prompt_title\",\n",
        "                \"prompt_text\",\"prompt_length\",\n",
        "                \"avg_word_length\",\"semicolon_count\",\"neg\",\"neu\",\"pos\",\"compound\",\n",
        "                \"exclamation_count\",\"question_count\",\"punctuation_sum\",\"neg_prompt\",\"neu_prompt\",\"pos_prompt\",\n",
        "                \"compound_prompt\",\"flesch_reading_ease\",\"flesch_kincaid_grade\",\"gunning_fog\",\"automated_readability_index\",\n",
        "                \"coleman_liau_index\",\"linsear_write_formula\",\"dale_chall_readability_score\",\"text_standard\",\"spache_readability\",\n",
        "                \"mcalpine_eflaw\"\n",
        "               ] + targets\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model_dict = {}\n",
        "\n",
        "for target in targets:\n",
        "    models = []\n",
        "\n",
        "    for fold in range(4):\n",
        "\n",
        "        X_train_cv = train[train[\"fold\"] != fold].drop(columns=drop_columns)\n",
        "        y_train_cv = train[train[\"fold\"] != fold][target]\n",
        "\n",
        "        features_pred = all_preds[all_preds[\"fold\"] != fold].drop(columns=['content','wording','fold'])\n",
        "        X_train_cv = pd.concat([X_train_cv,features_pred],axis=1)\n",
        "\n",
        "        X_eval_cv = train[train[\"fold\"] == fold].drop(columns=drop_columns)\n",
        "        y_eval_cv = train[train[\"fold\"] == fold][target]\n",
        "\n",
        "        features_pred = all_preds[all_preds[\"fold\"] == fold].drop(columns=['content','wording','fold'])\n",
        "        X_eval_cv = pd.concat([X_eval_cv,features_pred],axis=1)\n",
        "\n",
        "        dtrain = lgb.Dataset(X_train_cv, label=y_train_cv)\n",
        "        dval = lgb.Dataset(X_eval_cv, label=y_eval_cv)\n",
        "\n",
        "        params = {\n",
        "                  'boosting_type': 'gbdt',\n",
        "                  'random_state': 42,\n",
        "                  'objective': 'regression',\n",
        "                  'metric': 'rmse',\n",
        "                  'learning_rate': 0.048,\n",
        "                  'lambda_l1': 0.0,\n",
        "                  'lambda_l2': 0.011\n",
        "                  }\n",
        "\n",
        "        evaluation_results = {}\n",
        "        model = lgb.train(params,\n",
        "                          num_boost_round=10000,\n",
        "                            #categorical_feature = categorical_features,\n",
        "                          valid_names=['train', 'valid'],\n",
        "                          train_set=dtrain,\n",
        "                          valid_sets=dval,\n",
        "                          callbacks=[\n",
        "                              lgb.early_stopping(stopping_rounds=30, verbose=True),\n",
        "                               lgb.log_evaluation(100),\n",
        "                              lgb.callback.record_evaluation(evaluation_results)\n",
        "                            ],\n",
        "                          )\n",
        "        models.append(model)\n",
        "\n",
        "    model_dict[target] = models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNcOiYgbrQK1",
        "outputId": "33e0765b-2ab7-4751-d98b-53467e3326da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000797 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3570\n",
            "[LightGBM] [Info] Number of data points in the train set: 5108, number of used features: 14\n",
            "[LightGBM] [Info] Start training from score 0.017606\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "Early stopping, best iteration is:\n",
            "[48]\ttrain's rmse: 0.420033\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000839 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3570\n",
            "[LightGBM] [Info] Number of data points in the train set: 5156, number of used features: 14\n",
            "[LightGBM] [Info] Start training from score -0.039959\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[100]\ttrain's rmse: 0.547879\n",
            "Early stopping, best iteration is:\n",
            "[78]\ttrain's rmse: 0.547834\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000841 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3570\n",
            "[LightGBM] [Info] Number of data points in the train set: 5169, number of used features: 14\n",
            "[LightGBM] [Info] Start training from score 0.013356\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[100]\ttrain's rmse: 0.451839\n",
            "Early stopping, best iteration is:\n",
            "[70]\ttrain's rmse: 0.44965\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001222 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3570\n",
            "[LightGBM] [Info] Number of data points in the train set: 6062, number of used features: 14\n",
            "[LightGBM] [Info] Start training from score -0.044904\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[100]\ttrain's rmse: 0.480541\n",
            "Early stopping, best iteration is:\n",
            "[79]\ttrain's rmse: 0.478883\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000963 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3570\n",
            "[LightGBM] [Info] Number of data points in the train set: 5108, number of used features: 14\n",
            "[LightGBM] [Info] Start training from score -0.031791\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[100]\ttrain's rmse: 0.538889\n",
            "Early stopping, best iteration is:\n",
            "[72]\ttrain's rmse: 0.538739\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000830 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3570\n",
            "[LightGBM] [Info] Number of data points in the train set: 5156, number of used features: 14\n",
            "[LightGBM] [Info] Start training from score -0.060941\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "Early stopping, best iteration is:\n",
            "[29]\ttrain's rmse: 0.73888\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000947 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3570\n",
            "[LightGBM] [Info] Number of data points in the train set: 5169, number of used features: 14\n",
            "[LightGBM] [Info] Start training from score 0.028040\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[100]\ttrain's rmse: 0.538869\n",
            "Early stopping, best iteration is:\n",
            "[75]\ttrain's rmse: 0.535773\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000977 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3570\n",
            "[LightGBM] [Info] Number of data points in the train set: 6062, number of used features: 14\n",
            "[LightGBM] [Info] Start training from score -0.168933\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[100]\ttrain's rmse: 0.660095\n",
            "Early stopping, best iteration is:\n",
            "[74]\ttrain's rmse: 0.657132\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cv\n",
        "rmses = []\n",
        "\n",
        "for target in targets:\n",
        "    models = model_dict[target]\n",
        "\n",
        "    preds = []\n",
        "    trues = []\n",
        "\n",
        "    for fold, model in enumerate(models):\n",
        "\n",
        "        X_eval_cv = train[train[\"fold\"] == fold].drop(columns=drop_columns)\n",
        "        y_eval_cv = train[train[\"fold\"] == fold][target]\n",
        "        features_pred = all_preds[all_preds[\"fold\"] == fold].drop(columns=['content','wording','fold'])\n",
        "        X_eval_cv = pd.concat([X_eval_cv,features_pred],axis=1)\n",
        "\n",
        "        pred = model.predict(X_eval_cv)\n",
        "\n",
        "        trues.extend(y_eval_cv)\n",
        "        preds.extend(pred)\n",
        "\n",
        "    rmse = np.sqrt(mean_squared_error(trues, preds))\n",
        "    print(f\"{target}_rmse : {rmse}\")\n",
        "    rmses = rmses + [rmse]\n",
        "\n",
        "print(f\"mcrmse : {sum(rmses) / len(rmses)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6KgSMMsszYO",
        "outputId": "b0462e1b-9d12-4d89-9ba6-562c85b692d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content_rmse : 0.47584624950360127\n",
            "wording_rmse : 0.6187444225296523\n",
            "mcrmse : 0.5472953360166268\n"
          ]
        }
      ]
    }
  ]
}
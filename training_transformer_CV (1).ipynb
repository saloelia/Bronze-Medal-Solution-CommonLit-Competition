{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "weNB-8NzO3zo"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFWqX1faOsO9"
      },
      "outputs": [],
      "source": [
        "EPOCHS=5\n",
        "BATCH_SIZE=8\n",
        "max_length=1024\n",
        "PATH_TO_FOLDER = f'/content/drive/MyDrive/CommonLit/deberta-v3-base/question_title_text/batch_{BATCH_SIZE}/{max_length}'\n",
        "START_IN_FOLD = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6N8q38wJdPv"
      },
      "outputs": [],
      "source": [
        "os.makedirs(PATH_TO_FOLDER,exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aj43fvUVQnG1"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90JjHzUjV-kC"
      },
      "outputs": [],
      "source": [
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N6iSyx5jggkZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import gc\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import KFold,GroupKFold\n",
        "import tqdm.notebook as tq\n",
        "import logging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XaeuMoDXQ964"
      },
      "outputs": [],
      "source": [
        "# !pip install kaggle --upgrade\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "peYYMaPmQyjp"
      },
      "outputs": [],
      "source": [
        "!kaggle competitions download -c commonlit-evaluate-student-summaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tyTnHi5-SO7N"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile(\"/content/commonlit-evaluate-student-summaries.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"/content/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J81ZXACmjBcT"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "tokenizer = AutoTokenizer.from_pretrained('microsoft/deberta-v3-base')\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "npqY-fNLggka"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('/content/summaries_train.csv')\n",
        "prompts_train = pd.read_csv('/content/prompts_train.csv')\n",
        "data = data.merge(prompts_train, on='prompt_id', how='left')\n",
        "\n",
        "data['question_title_text'] = data['prompt_question'] + ' ' + tokenizer.sep_token + ' ' + data['prompt_title'] + ' ' + tokenizer.sep_token + ' ' + data['text']\n",
        "\n",
        "\n",
        "X = data['question_title_text'].to_list()\n",
        "y = data[['wording', 'content']].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O3QdxTQiggkc"
      },
      "outputs": [],
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self,hidden_units=768):\n",
        "        super(Model, self).__init__()\n",
        "        self.transformer = AutoModel.from_pretrained('microsoft/deberta-v3-base')\n",
        "        self.transformer.gradient_checkpointing_enable()\n",
        "        self.linear1 = nn.Linear(768, 768)\n",
        "        self.linear2 = nn.Linear(768, 2)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "        model_output = self.transformer(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        embeddings = self.mean_pooling(model_output, attention_mask)\n",
        "        output = self.linear1(embeddings)\n",
        "        output = nn.ReLU()(output)\n",
        "        output = self.linear2(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "    def mean_pooling(self,model_output, attention_mask):\n",
        "        token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
        "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
        "        return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6b4eMPMggkd"
      },
      "outputs": [],
      "source": [
        "def train_model(model,optimizer,criterion,train_loader,val_loader,fold,epochs=10):\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    true_word = []\n",
        "    true_content = []\n",
        "    pred_word = []\n",
        "    pred_content = []\n",
        "\n",
        "    file = open(f\"{PATH_TO_FOLDER}/fold_{fold}_log.txt\",\"w\")\n",
        "\n",
        "    for epoch in (range(epochs)):\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "        running_loss = 0.0\n",
        "        print(f\"\\n\")\n",
        "        print(f\"Epoch: {epoch+1}\")\n",
        "        file.write(f\"Epoch: {epoch+1}\")\n",
        "        file.write(\"\\n\")\n",
        "        for step, (input_ids, attention_mask, wording, content) in (enumerate(tq.tqdm(train_loader))):\n",
        "            gc.collect()\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "            input_ids = input_ids.to(device)\n",
        "            attention_mask = attention_mask.to(device)\n",
        "            content = content.float().to(device)\n",
        "            wording = wording.float().to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(input_ids, attention_mask)\n",
        "            loss = criterion(outputs[:, 0], wording) + criterion(outputs[:, 1], content)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            outputs = outputs.detach().cpu().numpy()\n",
        "            wording = wording.detach().cpu().numpy()\n",
        "            content = content.detach().cpu().numpy()\n",
        "\n",
        "            true_word.append(wording)\n",
        "            true_content.append(content)\n",
        "\n",
        "            pred_word.append(outputs[:, 0])\n",
        "            pred_content.append(outputs[:, 1])\n",
        "\n",
        "\n",
        "\n",
        "        t_w = [float(item) for sublist in true_word for item in sublist]\n",
        "        t_c = [float(item) for sublist in true_content for item in sublist]\n",
        "        p_w = [float(item) for sublist in pred_word for item in sublist]\n",
        "        p_c = [float(item) for sublist in pred_content for item in sublist]\n",
        "\n",
        "\n",
        "        print(\"\\n\")\n",
        "        print(f\"Train Statistic: Loss:{running_loss/len(train_loader)}, MCRMSE: {(mean_squared_error(t_w,p_w,squared=False)+mean_squared_error(t_c,p_c,squared=False))/2}, Wording: {mean_squared_error(t_w,p_w,squared=False)},Content:{mean_squared_error(t_c,p_c,squared=False)}\")\n",
        "        file.write(\"\\n\")\n",
        "        file.write(f\"Train Statistic: Loss:{running_loss/len(train_loader)}, MCRMSE: {(mean_squared_error(t_w,p_w,squared=False)+mean_squared_error(t_c,p_c,squared=False))/2}, Wording: {mean_squared_error(t_w,p_w,squared=False)},Content:{mean_squared_error(t_c,p_c,squared=False)}\")\n",
        "        file.write(\"\\n\")\n",
        "\n",
        "        # Validation loop\n",
        "        model.eval()\n",
        "\n",
        "\n",
        "        true_word = []\n",
        "        true_content = []\n",
        "        pred_word = []\n",
        "        pred_content = []\n",
        "\n",
        "\n",
        "        with torch.no_grad():\n",
        "            val_loss = 0.0\n",
        "\n",
        "            for val_step, (input_ids, attention_mask, wording, content) in enumerate(tq.tqdm(val_loader)):\n",
        "                gc.collect()\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "                input_ids = input_ids.to(device)\n",
        "                attention_mask = attention_mask.to(device)\n",
        "\n",
        "                content = content.float().to(device)\n",
        "                wording = wording.float().to(device)\n",
        "\n",
        "                outputs = model(input_ids, attention_mask)\n",
        "                loss = criterion(outputs[:, 0], wording) + criterion(outputs[:, 1], content)\n",
        "\n",
        "                val_loss += loss.item()\n",
        "\n",
        "                outputs = outputs.detach().cpu().numpy()\n",
        "                wording = wording.detach().cpu().numpy()\n",
        "                content = content.detach().cpu().numpy()\n",
        "\n",
        "                true_word.append(wording)\n",
        "                true_content.append(content)\n",
        "\n",
        "                pred_word.append(outputs[:, 0])\n",
        "                pred_content.append(outputs[:, 1])\n",
        "\n",
        "\n",
        "            t_w = [float(item) for sublist in true_word for item in sublist]\n",
        "            t_c = [float(item) for sublist in true_content for item in sublist]\n",
        "            p_w = [float(item) for sublist in pred_word for item in sublist]\n",
        "            p_c = [float(item) for sublist in pred_content for item in sublist]\n",
        "            gc.collect()\n",
        "            torch.cuda.empty_cache()\n",
        "            print(\"\\n\")\n",
        "            print(f\"Validation Statistic: Loss:{val_loss/len(val_loader)}, MCRMSE: {(mean_squared_error(t_w,p_w,squared=False)+mean_squared_error(t_c,p_c,squared=False))/2}, Wording: {mean_squared_error(t_w,p_w,squared=False)},Content:{mean_squared_error(t_c,p_c,squared=False)}\")\n",
        "            file.write(\"\\n\")\n",
        "            file.write(f\"Validation Statistic: Loss:{val_loss/len(val_loader)}, MCRMSE: {(mean_squared_error(t_w,p_w,squared=False)+mean_squared_error(t_c,p_c,squared=False))/2}, Wording: {mean_squared_error(t_w,p_w,squared=False)},Content:{mean_squared_error(t_c,p_c,squared=False)}\")\n",
        "            file.write(\"\\n\")\n",
        "\n",
        "    file.close()\n",
        "    print(f\"End of Training fold {fold}! \\n\")\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9m2_bLrZgwGY"
      },
      "outputs": [],
      "source": [
        "def save_df(model,loader,fold,test_index):\n",
        "    model.eval()\n",
        "    print(f\"Saving Dataframe of Fold {fold}...\")\n",
        "    true_word = []\n",
        "    true_content = []\n",
        "    pred_word = []\n",
        "    pred_content = []\n",
        "    with torch.no_grad():\n",
        "        for val_step, (input_ids, attention_mask, wording, content) in enumerate(tq.tqdm(loader)):\n",
        "\n",
        "\n",
        "            input_ids = input_ids.to(device)\n",
        "            attention_mask = attention_mask.to(device)\n",
        "            content = content.float().to(device)\n",
        "            wording = wording.float().to(device)\n",
        "            outputs = model(input_ids, attention_mask)\n",
        "\n",
        "            wording = wording.detach().cpu().numpy()\n",
        "            content = content.detach().cpu().numpy()\n",
        "\n",
        "            true_word.append(wording)\n",
        "            true_content.append(content)\n",
        "\n",
        "            outputs = outputs.detach().cpu().numpy()\n",
        "\n",
        "            pred_word.append(outputs[:, 0])\n",
        "            pred_content.append(outputs[:, 1])\n",
        "\n",
        "\n",
        "    df = pd.DataFrame()\n",
        "    df['idx'] = test_index\n",
        "    df['true_word'] = [float(item) for sublist in true_word for item in sublist]\n",
        "    df['true_content'] = [float(item) for sublist in true_content for item in sublist]\n",
        "    df['pred_word'] = [float(item) for sublist in pred_word for item in sublist]\n",
        "    df['pred_content'] = [float(item) for sublist in pred_content for item in sublist]\n",
        "    df.to_csv(PATH_TO_FOLDER+f'/predictions_fold_{fold}.csv',index=False)\n",
        "    print(f\"Dataframe Saved!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "referenced_widgets": [
            "83bcaa7728294576aa9d1510092f975e",
            "9f3c4205baad4aaeb6dc24ea9b23e6f7",
            "768fc5fb0ce84047beb685bcf1bd3037",
            "655a5ad9b0db4777a36142ab88241c5f",
            "a34c4446ea5a4b3688497e7433a22c60",
            "b9370599d6b748749aead99efd9a0c6e",
            "c24d74568c694884b56793681913a362",
            "9fbb0660da2f4e7894bc030a8e18b372",
            "99c7c95272934865bb5a466f1e268c9a",
            "d6b43a5915c841588f6436da811bcba2",
            "117c5a3c47d64dc893449c5e6d73a29e",
            "f64cf354227e480e80060d2c453336a6",
            "0b5b452054974245a58b4da82c8f6849",
            "b950a27541824a52804410dcbff844b2",
            "db803e453819461caf31f69a6cfd3ed6",
            "05303ecabf234753847f68ea23fdab0f",
            "d2b00486f3574ced8057d0421a070318",
            "0a2316f0152e4e8cb24d10b817ced604",
            "d51afa691b8e455dab8614d157bf7b64",
            "2aace98f522e4ab5ac3a9e0ff8b270ea",
            "a13ccce882ff48e3a1312739da5c3af7",
            "427c664b492c47519b5171c8e5f32d15",
            "8e60d7e97652498e8441e8fe66682aed",
            "beb5fda0b5e54509868f6a60c1f04f4c",
            "aaaac6696fc944eda2b1b14d7135109e",
            "965ebb9f170148a086821f52b03106c0"
          ]
        },
        "id": "IHFgxlAyggke",
        "outputId": "2e669489-7202-4882-8fdc-6ef2c9287d69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Begining Fold:1\n",
            "\n",
            "\n",
            "Epoch: 1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "83bcaa7728294576aa9d1510092f975e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/639 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Train Statistic: Loss:0.7565736637009142, MCRMSE: 0.6106313656977076, Wording: 0.6848668974584733,Content:0.5363958339369419\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9f3c4205baad4aaeb6dc24ea9b23e6f7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/258 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Validation Statistic: Loss:0.501861062016367, MCRMSE: 0.49448747639685126, Wording: 0.5779221789742292,Content:0.41105277381947336\n",
            "\n",
            "\n",
            "Epoch: 2\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "768fc5fb0ce84047beb685bcf1bd3037",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/639 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Train Statistic: Loss:0.47502384983084756, MCRMSE: 0.48599435123854606, Wording: 0.5585957114631662,Content:0.4133929910139259\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "655a5ad9b0db4777a36142ab88241c5f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/258 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Validation Statistic: Loss:0.525160882015561, MCRMSE: 0.5031805996286551, Wording: 0.6027565536197034,Content:0.4036046456376068\n",
            "\n",
            "\n",
            "Epoch: 3\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a34c4446ea5a4b3688497e7433a22c60",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/639 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Train Statistic: Loss:0.37811616618122107, MCRMSE: 0.45342152648333944, Wording: 0.5216364206899494,Content:0.38520663227672947\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b9370599d6b748749aead99efd9a0c6e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/258 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Validation Statistic: Loss:0.4770433412099531, MCRMSE: 0.4848406146790982, Wording: 0.5457434190137912,Content:0.4239378103444052\n",
            "\n",
            "\n",
            "Epoch: 4\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c24d74568c694884b56793681913a362",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/639 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Train Statistic: Loss:0.30716138138364363, MCRMSE: 0.4193279203444227, Wording: 0.46664912703491923,Content:0.3720067136539262\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9fbb0660da2f4e7894bc030a8e18b372",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/258 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Validation Statistic: Loss:0.4535264494114144, MCRMSE: 0.47319878084022804, Wording: 0.5253114952284166,Content:0.42108606645203944\n",
            "\n",
            "\n",
            "Epoch: 5\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "99c7c95272934865bb5a466f1e268c9a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/639 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Train Statistic: Loss:0.22821056107073695, MCRMSE: 0.38099208638152404, Wording: 0.4170776177583563,Content:0.3449065550046918\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d6b43a5915c841588f6436da811bcba2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/258 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Validation Statistic: Loss:0.5202155047377874, MCRMSE: 0.5040887518195233, Wording: 0.5826314074244541,Content:0.42554609621459244\n",
            "End of Training fold 1! \n",
            "\n",
            "Saving Dataframe of Fold 1...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "117c5a3c47d64dc893449c5e6d73a29e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/258 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataframe Saved!\n",
            "Begining Fold:2\n",
            "\n",
            "\n",
            "Epoch: 1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f64cf354227e480e80060d2c453336a6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/645 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Train Statistic: Loss:0.6991671571551368, MCRMSE: 0.5881713820078742, Wording: 0.6498688405952966,Content:0.526473923420452\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0b5b452054974245a58b4da82c8f6849",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/252 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Validation Statistic: Loss:1.311111904089413, MCRMSE: 0.7907431120368139, Wording: 0.9673939397682576,Content:0.6140922843053702\n",
            "\n",
            "\n",
            "Epoch: 2\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b950a27541824a52804410dcbff844b2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/645 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Train Statistic: Loss:0.4353220387831215, MCRMSE: 0.5752042514998708, Wording: 0.67475231784006,Content:0.47565618515968144\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "db803e453819461caf31f69a6cfd3ed6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/252 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Validation Statistic: Loss:0.973330748814439, MCRMSE: 0.6885235444667511, Wording: 0.8014700992541492,Content:0.575576989679353\n",
            "\n",
            "\n",
            "Epoch: 3\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "05303ecabf234753847f68ea23fdab0f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/645 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Train Statistic: Loss:0.33976086584865584, MCRMSE: 0.5038316369711533, Wording: 0.5731506467027614,Content:0.4345126272395453\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d2b00486f3574ced8057d0421a070318",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/252 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Validation Statistic: Loss:0.8478601492113538, MCRMSE: 0.6392233890948986, Wording: 0.7655714465944793,Content:0.5128753315953181\n",
            "\n",
            "\n",
            "Epoch: 4\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0a2316f0152e4e8cb24d10b817ced604",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/645 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Train Statistic: Loss:0.2614091870223367, MCRMSE: 0.45723453376144285, Wording: 0.5206193597049239,Content:0.39384970781796186\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d51afa691b8e455dab8614d157bf7b64",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/252 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Validation Statistic: Loss:0.7523408241806522, MCRMSE: 0.6050724686333612, Wording: 0.708926992139068,Content:0.5012179451276544\n",
            "\n",
            "\n",
            "Epoch: 5\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2aace98f522e4ab5ac3a9e0ff8b270ea",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/645 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Train Statistic: Loss:0.18631246358502743, MCRMSE: 0.4127466278491544, Wording: 0.4612275364028695,Content:0.36426571929543927\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a13ccce882ff48e3a1312739da5c3af7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/252 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Validation Statistic: Loss:0.8376662787345667, MCRMSE: 0.6351630441581149, Wording: 0.7629660980458561,Content:0.5073599902703736\n",
            "End of Training fold 2! \n",
            "\n",
            "Saving Dataframe of Fold 2...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "427c664b492c47519b5171c8e5f32d15",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/252 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataframe Saved!\n",
            "Begining Fold:3\n",
            "\n",
            "\n",
            "Epoch: 1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8e60d7e97652498e8441e8fe66682aed",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/647 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Train Statistic: Loss:0.7621167649556717, MCRMSE: 0.6129745872740138, Wording: 0.6891140921647586,Content:0.5368350823832689\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "beb5fda0b5e54509868f6a60c1f04f4c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/250 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Validation Statistic: Loss:0.5411752920746803, MCRMSE: 0.5171730667756156, Wording: 0.5701595807842516,Content:0.4641865527669795\n",
            "\n",
            "\n",
            "Epoch: 2\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aaaac6696fc944eda2b1b14d7135109e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/647 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Train Statistic: Loss:0.4633470796958372, MCRMSE: 0.48821483390370884, Wording: 0.5535450404378924,Content:0.42288462736952526\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "965ebb9f170148a086821f52b03106c0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/250 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "group_kfold = GroupKFold(n_splits=4)\n",
        "folds = {'39c16e':0,\n",
        "         '3b9047':1,\n",
        "         'ebad26':2,\n",
        "         '814d6b':3\n",
        "}\n",
        "groups = np.array([folds[data['prompt_id'][i]] for i in range(len(data))])\n",
        "\n",
        "for fold, (train_index, test_index) in (enumerate(group_kfold.split(X, y, groups))):\n",
        "\n",
        "    train_encodings = tokenizer.batch_encode_plus(\n",
        "    data['question_title_text'][train_index].tolist(),\n",
        "    max_length=max_length,\n",
        "    truncation=True,\n",
        "    padding=True\n",
        ")\n",
        "    val_encodings = tokenizer.batch_encode_plus(\n",
        "    data['question_title_text'][test_index].tolist(),\n",
        "    max_length=max_length,\n",
        "    truncation=True,\n",
        "    padding=True\n",
        ")\n",
        "\n",
        "    train_dataset = torch.utils.data.TensorDataset(\n",
        "    torch.tensor(train_encodings['input_ids']),\n",
        "    torch.tensor(train_encodings['attention_mask']),\n",
        "    torch.tensor(data['wording'][train_index].tolist()),\n",
        "    torch.tensor(data['content'][train_index].tolist())\n",
        ")\n",
        "    validation_dataset = torch.utils.data.TensorDataset(\n",
        "    torch.tensor(val_encodings['input_ids']),\n",
        "    torch.tensor(val_encodings['attention_mask']),\n",
        "    torch.tensor(data['wording'][test_index].tolist()),\n",
        "    torch.tensor(data['content'][test_index].tolist())\n",
        ")\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    if START_IN_FOLD<=(fold+1):\n",
        "        print(f'Begining Fold:{fold+1}')\n",
        "        model = Model().to(device)\n",
        "        optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
        "        criterion = nn.MSELoss()\n",
        "\n",
        "        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,drop_last=False)\n",
        "        val_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=False,drop_last=False)\n",
        "\n",
        "        model = train_model(model,optimizer,criterion,train_loader,val_loader,fold+1,EPOCHS)\n",
        "\n",
        "        torch.save({\n",
        "            'fold':fold+1,\n",
        "            'model_state_dict': model.state_dict()\n",
        "            # 'epoch':best_epoch\n",
        "        },PATH_TO_FOLDER+f'/fold_{fold+1}')\n",
        "\n",
        "\n",
        "        save_df(model,val_loader,fold+1,test_index)\n",
        "\n",
        "# print(\"\\n\")\n",
        "# print(\"\\n\")\n",
        "# print(f\"MSRMSE:{np.mean(mcrmse)}\")\n",
        "# print(f\"Wording:{np.mean(wording)}\")\n",
        "# print(f\"Content:{np.mean(content)}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
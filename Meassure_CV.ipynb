{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "41167715be054b0c860cd75b39c26331": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_55e587febabe433ebe2f3b889b3d49fa",
              "IPY_MODEL_b185f8f9d1bd4630a8c043a67dc23882",
              "IPY_MODEL_fdd5f71e1630473880fbe1da349d155d"
            ],
            "layout": "IPY_MODEL_c8974246ae9e4ddfa0058499393e85c0"
          }
        },
        "55e587febabe433ebe2f3b889b3d49fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ace9609366847d4bbf66d1ad732eb3a",
            "placeholder": "​",
            "style": "IPY_MODEL_319d9cb4241445eaa2c8f67c7df9806e",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "b185f8f9d1bd4630a8c043a67dc23882": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84c3c7b9234e45dcbce47d73de489dd2",
            "max": 363,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6ddb10f2b7254da3b3cd2786dfd8f83a",
            "value": 363
          }
        },
        "fdd5f71e1630473880fbe1da349d155d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d2f2b84d12b49ddb9f8cc5493fef2dc",
            "placeholder": "​",
            "style": "IPY_MODEL_559da5e40ea14ae4acfdffb075c58f9c",
            "value": " 363/363 [00:00&lt;00:00, 31.1kB/s]"
          }
        },
        "c8974246ae9e4ddfa0058499393e85c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ace9609366847d4bbf66d1ad732eb3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "319d9cb4241445eaa2c8f67c7df9806e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84c3c7b9234e45dcbce47d73de489dd2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ddb10f2b7254da3b3cd2786dfd8f83a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0d2f2b84d12b49ddb9f8cc5493fef2dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "559da5e40ea14ae4acfdffb075c58f9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "55f46fdab557498eb2ced9a19c927f29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0313ab5b03a74191bb094d1734ceabc6",
              "IPY_MODEL_7781736bb99b4f469cce9ed8fcc76149",
              "IPY_MODEL_f88f2fd3e4964e8095d01b098e020d03"
            ],
            "layout": "IPY_MODEL_47cd99387ffc47779653ca93dfe9fc39"
          }
        },
        "0313ab5b03a74191bb094d1734ceabc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7dce40a1d61b453f84135caddc97904f",
            "placeholder": "​",
            "style": "IPY_MODEL_03763975bef74ffe8b6a52d93a656e58",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "7781736bb99b4f469cce9ed8fcc76149": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_610bce460b724412bab8925c722766c9",
            "max": 231536,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_664c8da242234c369aa5ef6901b48f66",
            "value": 231536
          }
        },
        "f88f2fd3e4964e8095d01b098e020d03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d23da3bd35b742c5899191bb0b20c3dc",
            "placeholder": "​",
            "style": "IPY_MODEL_3db0b61cee5a43d5a847d6556f3683a2",
            "value": " 232k/232k [00:00&lt;00:00, 13.2MB/s]"
          }
        },
        "47cd99387ffc47779653ca93dfe9fc39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7dce40a1d61b453f84135caddc97904f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03763975bef74ffe8b6a52d93a656e58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "610bce460b724412bab8925c722766c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "664c8da242234c369aa5ef6901b48f66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d23da3bd35b742c5899191bb0b20c3dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3db0b61cee5a43d5a847d6556f3683a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "74502a8194784745a9439c4fecd6d73e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c140817740c5445398a951368d9fd4ab",
              "IPY_MODEL_22285810066a48108d4d5eafef9120b2",
              "IPY_MODEL_054be9275f9348e59c9cb7ac44425f37"
            ],
            "layout": "IPY_MODEL_f598135392d2484ea60c70ab7e163c10"
          }
        },
        "c140817740c5445398a951368d9fd4ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79eb5156613b40f79711b21f11a5dd02",
            "placeholder": "​",
            "style": "IPY_MODEL_20e93ad8da52434b8bc35331d6b3c11e",
            "value": "Downloading (…)/main/tokenizer.json: 100%"
          }
        },
        "22285810066a48108d4d5eafef9120b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_259d6d4d6e0041218ff5a51d6f81def6",
            "max": 466021,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_30041aa081994382ab3d54ee9911d11f",
            "value": 466021
          }
        },
        "054be9275f9348e59c9cb7ac44425f37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e0d01ac8e6745aaa24687bfeb767338",
            "placeholder": "​",
            "style": "IPY_MODEL_119c8fb854e241338a5d827e71f702ed",
            "value": " 466k/466k [00:00&lt;00:00, 33.3MB/s]"
          }
        },
        "f598135392d2484ea60c70ab7e163c10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79eb5156613b40f79711b21f11a5dd02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20e93ad8da52434b8bc35331d6b3c11e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "259d6d4d6e0041218ff5a51d6f81def6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30041aa081994382ab3d54ee9911d11f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8e0d01ac8e6745aaa24687bfeb767338": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "119c8fb854e241338a5d827e71f702ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dab59b179ea448fdabb656509b2a25d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a90601e359d344fab991126047b2aa1d",
              "IPY_MODEL_b9fb5d342c0d4332848b78cfb79544e3",
              "IPY_MODEL_91b46a012cd74ecb839801f79292d411"
            ],
            "layout": "IPY_MODEL_5bdb5457164841cab4296fd5b82167f6"
          }
        },
        "a90601e359d344fab991126047b2aa1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58286e15afb4459ca19ab1b0542e6627",
            "placeholder": "​",
            "style": "IPY_MODEL_65845c0772794d5c91166e046cc6ee18",
            "value": "Downloading (…)cial_tokens_map.json: 100%"
          }
        },
        "b9fb5d342c0d4332848b78cfb79544e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da52ff015bce4843994ef5d32900c4bc",
            "max": 239,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a19d2ee338834cf190f48ae1ca0b1514",
            "value": 239
          }
        },
        "91b46a012cd74ecb839801f79292d411": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bda48d827a74437b8b36bb5a0be56262",
            "placeholder": "​",
            "style": "IPY_MODEL_4ecf826197074f4086859bdf49d8a45a",
            "value": " 239/239 [00:00&lt;00:00, 22.7kB/s]"
          }
        },
        "5bdb5457164841cab4296fd5b82167f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58286e15afb4459ca19ab1b0542e6627": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65845c0772794d5c91166e046cc6ee18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da52ff015bce4843994ef5d32900c4bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a19d2ee338834cf190f48ae1ca0b1514": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bda48d827a74437b8b36bb5a0be56262": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ecf826197074f4086859bdf49d8a45a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QF7QVZGpy8qQ",
        "outputId": "e94a0dc0-770b-4de7-e23e-892a868dbbe2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Install and Imports"
      ],
      "metadata": {
        "id": "s1zbreeA1hMN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade transformers\n",
        "!pip install sentencepiece\n",
        "!pip install textstat\n",
        "!pip install pyspellchecker\n",
        "!pip install datasets\n",
        "!pip install accelerate -U"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XH-sDLgz1bbp",
        "outputId": "c628da4d-5e6b-4b26-cbe4-f3227dcf2a71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.33.3-py3-none-any.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.15.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m110.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m85.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.17.3 safetensors-0.3.3 tokenizers-0.13.3 transformers-4.33.3\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.99\n",
            "Collecting textstat\n",
            "  Downloading textstat-0.7.3-py3-none-any.whl (105 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.1/105.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyphen (from textstat)\n",
            "  Downloading pyphen-0.14.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyphen, textstat\n",
            "Successfully installed pyphen-0.14.0 textstat-0.7.3\n",
            "Collecting pyspellchecker\n",
            "  Downloading pyspellchecker-0.7.2-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyspellchecker\n",
            "Successfully installed pyspellchecker-0.7.2\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.14.5-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.6/519.6 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.17.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, dill, multiprocess, datasets\n",
            "Successfully installed datasets-2.14.5 dill-0.3.7 multiprocess-0.70.15 xxhash-3.3.0\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.23.0-py3-none-any.whl (258 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.1/258.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1+cu118)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.17.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (16.0.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.23.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import warnings\n",
        "import logging\n",
        "import os\n",
        "import gc\n",
        "import shutil\n",
        "import json\n",
        "import transformers\n",
        "from transformers import AutoModel, AutoTokenizer, AutoConfig, AutoModelForSequenceClassification,EarlyStoppingCallback\n",
        "from transformers import DataCollatorWithPadding\n",
        "from datasets import Dataset,load_dataset, load_from_disk\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from datasets import load_metric, disable_progress_bar\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import torch\n",
        "from sklearn.model_selection import KFold, GroupKFold\n",
        "from tqdm import tqdm\n",
        "import textstat\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('vader_lexicon')\n",
        "from nltk import pos_tag,ne_chunk, word_tokenize\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "import spacy\n",
        "import re\n",
        "from spellchecker import SpellChecker\n",
        "import lightgbm as lgb\n",
        "\n",
        "import random\n",
        "# logging setting\n",
        "\n",
        "warnings.simplefilter(\"ignore\")\n",
        "logging.disable(logging.ERROR)\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "disable_progress_bar()\n",
        "tqdm.pandas()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxxLCm8F1eiJ",
        "outputId": "96099797-36b5-4f2b-89a5-27610887967a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEW4wqN7MlYx"
      },
      "source": [
        "###Device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52oiOSQOfqG8",
        "outputId": "629aab62-cafb-4b9a-fa6b-921b77b5381e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ctfO27vM7p3"
      },
      "source": [
        "###Set seed to 42"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZjU1fmyLM4vr"
      },
      "outputs": [],
      "source": [
        "# set random seed\n",
        "def seed_everything(seed: int):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "\n",
        "seed_everything(seed=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKSWcfaQNBVH"
      },
      "source": [
        "###Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_27XghLM-qx"
      },
      "outputs": [],
      "source": [
        "EXP_NUM = 1\n",
        "\n",
        "class CFG:\n",
        "    model_name=\"all-mpnet-base-v2\"\n",
        "    dir_model=\"sentence-transformers/\"\n",
        "    save_model_path = f'/content/{model_name}-model/exp_{EXP_NUM}'\n",
        "    learning_rate=0.000016\n",
        "    weight_decay=0.03\n",
        "    hidden_dropout_prob=0.07\n",
        "    attention_probs_dropout_prob=0.07\n",
        "    num_train_epochs=5\n",
        "    n_splits=4\n",
        "    batch_size=12\n",
        "    random_seed=42\n",
        "    save_steps=100\n",
        "    max_length=512\n",
        "    early_stopping_patience=20"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hwx5izVXNLl6"
      },
      "source": [
        "###Read Data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle competitions download -c commonlit-evaluate-student-summaries\n",
        "\n",
        "import zipfile\n",
        "with zipfile.ZipFile(\"/content/commonlit-evaluate-student-summaries.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"/content/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UqU4WF12dsJ",
        "outputId": "429088d8-f294-4097-ae41-a4a692b11c97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading commonlit-evaluate-student-summaries.zip to /content\n",
            " 95% 1.00M/1.05M [00:00<00:00, 1.09MB/s]\n",
            "100% 1.05M/1.05M [00:00<00:00, 1.14MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TBjFHTMINFen"
      },
      "outputs": [],
      "source": [
        "DATA_DIR = \"/content/\"\n",
        "\n",
        "prompts_train = pd.read_csv(DATA_DIR + \"prompts_train.csv\")\n",
        "prompts_test = pd.read_csv(DATA_DIR + \"prompts_test.csv\")\n",
        "summaries_train = pd.read_csv(DATA_DIR + \"summaries_train.csv\")\n",
        "summaries_test = pd.read_csv(DATA_DIR + \"summaries_test.csv\")\n",
        "sample_submission = pd.read_csv(DATA_DIR + \"sample_submission.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8g7AgjlPhGS"
      },
      "source": [
        "###Pre-processor Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "41167715be054b0c860cd75b39c26331",
            "55e587febabe433ebe2f3b889b3d49fa",
            "b185f8f9d1bd4630a8c043a67dc23882",
            "fdd5f71e1630473880fbe1da349d155d",
            "c8974246ae9e4ddfa0058499393e85c0",
            "7ace9609366847d4bbf66d1ad732eb3a",
            "319d9cb4241445eaa2c8f67c7df9806e",
            "84c3c7b9234e45dcbce47d73de489dd2",
            "6ddb10f2b7254da3b3cd2786dfd8f83a",
            "0d2f2b84d12b49ddb9f8cc5493fef2dc",
            "559da5e40ea14ae4acfdffb075c58f9c",
            "55f46fdab557498eb2ced9a19c927f29",
            "0313ab5b03a74191bb094d1734ceabc6",
            "7781736bb99b4f469cce9ed8fcc76149",
            "f88f2fd3e4964e8095d01b098e020d03",
            "47cd99387ffc47779653ca93dfe9fc39",
            "7dce40a1d61b453f84135caddc97904f",
            "03763975bef74ffe8b6a52d93a656e58",
            "610bce460b724412bab8925c722766c9",
            "664c8da242234c369aa5ef6901b48f66",
            "d23da3bd35b742c5899191bb0b20c3dc",
            "3db0b61cee5a43d5a847d6556f3683a2",
            "74502a8194784745a9439c4fecd6d73e",
            "c140817740c5445398a951368d9fd4ab",
            "22285810066a48108d4d5eafef9120b2",
            "054be9275f9348e59c9cb7ac44425f37",
            "f598135392d2484ea60c70ab7e163c10",
            "79eb5156613b40f79711b21f11a5dd02",
            "20e93ad8da52434b8bc35331d6b3c11e",
            "259d6d4d6e0041218ff5a51d6f81def6",
            "30041aa081994382ab3d54ee9911d11f",
            "8e0d01ac8e6745aaa24687bfeb767338",
            "119c8fb854e241338a5d827e71f702ed",
            "dab59b179ea448fdabb656509b2a25d4",
            "a90601e359d344fab991126047b2aa1d",
            "b9fb5d342c0d4332848b78cfb79544e3",
            "91b46a012cd74ecb839801f79292d411",
            "5bdb5457164841cab4296fd5b82167f6",
            "58286e15afb4459ca19ab1b0542e6627",
            "65845c0772794d5c91166e046cc6ee18",
            "da52ff015bce4843994ef5d32900c4bc",
            "a19d2ee338834cf190f48ae1ca0b1514",
            "bda48d827a74437b8b36bb5a0be56262",
            "4ecf826197074f4086859bdf49d8a45a"
          ]
        },
        "id": "0JHSgfOjPj8Z",
        "outputId": "4ef10465-85ab-4361-dbe4-ecf592291112"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "41167715be054b0c860cd75b39c26331"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "55f46fdab557498eb2ced9a19c927f29"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "74502a8194784745a9439c4fecd6d73e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dab59b179ea448fdabb656509b2a25d4"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "class Preprocessor:\n",
        "    def __init__(self,model_name: str,dir_model: str) -> None:\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(f\"{dir_model}{model_name}\")\n",
        "        self.STOP_WORDS = set(stopwords.words('english'))\n",
        "\n",
        "        self.spacy_ner_model = spacy.load('en_core_web_sm',)\n",
        "        self.speller = SpellChecker()\n",
        "\n",
        "    def count_text_length(self, df: pd.DataFrame, col:str) -> pd.Series:\n",
        "        \"\"\" text length \"\"\"\n",
        "        tokenizer=self.tokenizer\n",
        "        return df[col].progress_apply(lambda x: len(tokenizer.encode(x)))\n",
        "\n",
        "    #JUST STOP WORDS OVERLAP\n",
        "    def word_overlap_count(self, row):\n",
        "        \"\"\" intersection(prompt_text, text) \"\"\"\n",
        "        def check_is_stop_word(word):\n",
        "            return word in self.STOP_WORDS\n",
        "\n",
        "#         prompt_words = row['prompt_tokens']\n",
        "#         summary_words = row['summary_tokens']\n",
        "\n",
        "        prompt_words = list(self.spacy_ner_model.tokenizer(row['prompt_text']))\n",
        "        summary_words = list(self.spacy_ner_model.tokenizer(row['text']))\n",
        "\n",
        "        prompt_words = [str(word) for word in prompt_words]\n",
        "        summary_words = [str(word) for word in summary_words]\n",
        "\n",
        "        if self.STOP_WORDS:\n",
        "            prompt_words = list(filter(check_is_stop_word, prompt_words))\n",
        "            summary_words = list(filter(check_is_stop_word, summary_words))\n",
        "        return len(set(prompt_words).intersection(set(summary_words)))\n",
        "\n",
        "    #REAL OVERLAP WORD\n",
        "    def word_overlap_count_real(self, row):\n",
        "        \"\"\" intersection(prompt_text, text) \"\"\"\n",
        "        def check_is_stop_word_real(word):\n",
        "            return word not in self.STOP_WORDS\n",
        "\n",
        "        prompt_words = list(self.spacy_ner_model.tokenizer(row['prompt_text']))\n",
        "        summary_words = list(self.spacy_ner_model.tokenizer(row['text']))\n",
        "\n",
        "        prompt_words = [str(word) for word in prompt_words]\n",
        "        summary_words = [str(word) for word in summary_words]\n",
        "\n",
        "        if self.STOP_WORDS:\n",
        "            prompt_words = list(filter(check_is_stop_word_real, prompt_words))\n",
        "            summary_words = list(filter(check_is_stop_word_real, summary_words))\n",
        "        return len(set(prompt_words).intersection(set(summary_words)))\n",
        "\n",
        "\n",
        "    def ngrams(self, token, n):\n",
        "        # Use the zip function to help us generate n-grams\n",
        "        # Concatentate the tokens into ngrams and return\n",
        "        ngrams = zip(*[token[i:] for i in range(n)])\n",
        "        return [\" \".join(ngram) for ngram in ngrams]\n",
        "\n",
        "    def ngram_co_occurrence(self, row, n: int):\n",
        "        # Tokenize the original text and summary into words\n",
        "        original_tokens = row['prompt_tokens']\n",
        "        summary_tokens = row['summary_tokens']\n",
        "\n",
        "        # Generate n-grams for the original text and summary\n",
        "        original_ngrams = set(self.ngrams(original_tokens, n))\n",
        "        summary_ngrams = set(self.ngrams(summary_tokens, n))\n",
        "\n",
        "        # Calculate the number of common n-grams\n",
        "        common_ngrams = original_ngrams.intersection(summary_ngrams)\n",
        "\n",
        "        # # Optionally, you can get the frequency of common n-grams for a more nuanced analysis\n",
        "        # original_ngram_freq = Counter(ngrams(original_words, n))\n",
        "        # summary_ngram_freq = Counter(ngrams(summary_words, n))\n",
        "        # common_ngram_freq = {ngram: min(original_ngram_freq[ngram], summary_ngram_freq[ngram]) for ngram in common_ngrams}\n",
        "\n",
        "        return len(common_ngrams)\n",
        "\n",
        "    def ner_overlap_count(self, row, mode:str):\n",
        "        model = self.spacy_ner_model\n",
        "        def clean_ners(ner_list):\n",
        "            return set([(ner[0].lower(), ner[1]) for ner in ner_list])\n",
        "        prompt = model(row['prompt_text'])\n",
        "        summary = model(row['text'])\n",
        "\n",
        "        if \"spacy\" in str(model):\n",
        "            prompt_ner = set([(token.text, token.label_) for token in prompt.ents])\n",
        "            summary_ner = set([(token.text, token.label_) for token in summary.ents])\n",
        "        elif \"stanza\" in str(model):\n",
        "            prompt_ner = set([(token.text, token.type) for token in prompt.ents])\n",
        "            summary_ner = set([(token.text, token.type) for token in summary.ents])\n",
        "        else:\n",
        "            raise Exception(\"Model not supported\")\n",
        "\n",
        "        prompt_ner = clean_ners(prompt_ner)\n",
        "        summary_ner = clean_ners(summary_ner)\n",
        "\n",
        "        intersecting_ners = prompt_ner.intersection(summary_ner)\n",
        "\n",
        "        ner_dict = dict(Counter([ner[1] for ner in intersecting_ners]))\n",
        "\n",
        "        if mode == \"train\":\n",
        "            return ner_dict\n",
        "        elif mode == \"test\":\n",
        "            return {key: ner_dict.get(key) for key in self.ner_keys}\n",
        "\n",
        "\n",
        "    def quotes_count(self, row):\n",
        "        summary = row['text']\n",
        "        text = row['prompt_text']\n",
        "        quotes_from_summary = re.findall(r'\"([^\"]*)\"', summary)\n",
        "        if len(quotes_from_summary)>0:\n",
        "            return [quote in text for quote in quotes_from_summary].count(True)\n",
        "        else:\n",
        "            return 0\n",
        "\n",
        "    def spelling(self, text):\n",
        "\n",
        "#         wordlist=text.split()\n",
        "        wordlist = self.spacy_ner_model.tokenizer(text)\n",
        "        wordlist = [str(word) for word in wordlist]\n",
        "        amount_miss = len(list(self.speller.unknown(wordlist)))\n",
        "\n",
        "        return amount_miss\n",
        "\n",
        "\n",
        "    def calculate_pos_ratios(self,text):\n",
        "        pos_tags = pos_tag(nltk.word_tokenize(text))\n",
        "        pos_counts = Counter(tag for word, tag in pos_tags)\n",
        "        total_words = len(pos_tags)\n",
        "        ratios = {tag: count / total_words for tag, count in pos_counts.items()}\n",
        "        return ratios\n",
        "\n",
        "    def calculate_sentiment_scores(self,text):\n",
        "        sid = SentimentIntensityAnalyzer()\n",
        "        sentiment_scores = sid.polarity_scores(text)\n",
        "        return sentiment_scores\n",
        "\n",
        "    def calculate_punctuation_ratios(self,text):\n",
        "        total_chars = len(text)\n",
        "        punctuation_counts = Counter(char for char in text if char in '.,!?;:\"()[]{}')\n",
        "        ratios = {char: count / total_chars for char, count in punctuation_counts.items()}\n",
        "        return ratios\n",
        "\n",
        "    def calculate_keyword_density(self,row):\n",
        "        keywords = set(row['prompt_text'].split())\n",
        "        text_words = row['text'].split()\n",
        "        keyword_count = sum(1 for word in text_words if word in keywords)\n",
        "        return keyword_count / len(text_words)\n",
        "\n",
        "\n",
        "    def run(self,prompts: pd.DataFrame,summaries:pd.DataFrame,mode:str) -> pd.DataFrame:\n",
        "\n",
        "        # before merge preprocess\n",
        "\n",
        "#         prompts[\"prompt_length\"] = prompts[\"prompt_text\"].apply(\n",
        "#             lambda x: len(self.tokenizer.encode(x))\n",
        "#         )\n",
        "\n",
        "        prompts[\"prompt_length\"] = prompts[\"prompt_text\"].apply(\n",
        "            lambda x: len(list(self.spacy_ner_model.tokenizer(x)))\n",
        "        )\n",
        "\n",
        "        prompts[\"prompt_tokens\"] = prompts[\"prompt_text\"].apply(\n",
        "            lambda x: self.tokenizer.convert_ids_to_tokens(\n",
        "                self.tokenizer.encode(x),\n",
        "                skip_special_tokens=True\n",
        "            )\n",
        "        )\n",
        "\n",
        "#         summaries[\"summary_length\"] = summaries[\"text\"].apply(\n",
        "#             lambda x: len(self.tokenizer.encode(x))\n",
        "#         )\n",
        "\n",
        "        summaries[\"summary_length\"] = summaries[\"text\"].apply(\n",
        "            lambda x: len(list(self.spacy_ner_model.tokenizer(x)))\n",
        "        )\n",
        "\n",
        "        summaries[\"summary_tokens\"] = summaries[\"text\"].apply(\n",
        "            lambda x: self.tokenizer.convert_ids_to_tokens(\n",
        "                self.tokenizer.encode(x),\n",
        "                skip_special_tokens=True\n",
        "            )\n",
        "\n",
        "        )\n",
        "        summaries[\"splling_err_num\"] = summaries[\"text\"].progress_apply(self.spelling)\n",
        "\n",
        "        # merge prompts and summaries\n",
        "        input_df = summaries.merge(prompts, how=\"left\", on=\"prompt_id\")\n",
        "\n",
        "        # after merge preprocess\n",
        "        input_df['length_ratio'] = input_df['summary_length'] / input_df['prompt_length']\n",
        "\n",
        "        #stop words overlap\n",
        "        input_df['word_overlap_count'] = input_df.progress_apply(self.word_overlap_count, axis=1)\n",
        "\n",
        "\n",
        "        input_df['bigram_overlap_count'] = input_df.progress_apply(\n",
        "            self.ngram_co_occurrence,args=(2,), axis=1\n",
        "        )\n",
        "        input_df['trigram_overlap_count'] = input_df.progress_apply(\n",
        "            self.ngram_co_occurrence, args=(3,), axis=1\n",
        "        )\n",
        "\n",
        "#         # Crate dataframe with count of each category NERs overlap for all the summaries\n",
        "#         # Because it spends too much time for this feature, I don't use this time.\n",
        "#         ners_count_df  = input_df.progress_apply(\n",
        "#             lambda row: pd.Series(self.ner_overlap_count(row, mode=mode), dtype='float64'), axis=1\n",
        "#         ).fillna(0)\n",
        "#         self.ner_keys = ners_count_df.columns\n",
        "#         ners_count_df['sum'] = ners_count_df.sum(axis=1)\n",
        "#         ners_count_df.columns = ['NER_' + col for col in ners_count_df.columns]\n",
        "#         # join ner count dataframe with train dataframe\n",
        "#         input_df = pd.concat([input_df, ners_count_df], axis=1)\n",
        "\n",
        "        input_df['quotes_count'] = input_df.progress_apply(self.quotes_count, axis=1)\n",
        "\n",
        "        #Additional\n",
        "\n",
        "        #real overlap words\n",
        "        input_df['real_word_overlap_count'] = input_df.progress_apply(self.word_overlap_count_real, axis=1)\n",
        "\n",
        "        input_df['sentence_length'] = input_df['text'].progress_apply(lambda x: len(x.split('.')))\n",
        "        input_df['vocabulary_richness'] = input_df['text'].progress_apply(lambda x: len(set(x.split())))\n",
        "        input_df['avg_word_length'] = input_df['text'].progress_apply(lambda x: np.mean([len(word) for word in x.split()]))\n",
        "        input_df['comma_count'] = input_df['text'].progress_apply(lambda x: x.count(','))\n",
        "        input_df['semicolon_count'] = input_df['text'].progress_apply(lambda x: x.count(';'))\n",
        "\n",
        "        input_df['pos_ratios'] = input_df['text'].progress_apply(self.calculate_pos_ratios)\n",
        "        input_df['pos_mean'] = input_df['pos_ratios'].progress_apply(lambda x: np.mean(list(x.values())))\n",
        "\n",
        "        input_df['sentiment_scores'] = input_df['text'].progress_apply(self.calculate_sentiment_scores)\n",
        "\n",
        "        sentiment_columns = pd.DataFrame(list(input_df['sentiment_scores']))\n",
        "        input_df = pd.concat([input_df, sentiment_columns], axis=1)\n",
        "\n",
        "        input_df['exclamation_count'] = input_df['text'].progress_apply(lambda x: x.count('!'))\n",
        "        input_df['question_count'] = input_df['text'].progress_apply(lambda x: x.count('?'))\n",
        "        input_df['quote_count'] = input_df['text'].progress_apply(lambda x: x.count('\"'))\n",
        "\n",
        "        input_df['punctuation_ratios'] = input_df['text'].progress_apply(self.calculate_punctuation_ratios)\n",
        "        input_df['punctuation_sum'] = input_df['punctuation_ratios'].progress_apply(lambda x: np.sum(list(x.values())))\n",
        "\n",
        "        input_df['keyword_density'] = input_df.progress_apply(self.calculate_keyword_density, axis=1)\n",
        "\n",
        "        input_df['sentiment_scores_prompt'] = input_df['prompt_text'].progress_apply(self.calculate_sentiment_scores)\n",
        "\n",
        "        sentiment_columns_prompt = pd.DataFrame(list(input_df['sentiment_scores_prompt']))\n",
        "        sentiment_columns_prompt.columns = [col +'_prompt' for col in sentiment_columns_prompt.columns]\n",
        "\n",
        "        input_df = pd.concat([input_df, sentiment_columns_prompt], axis=1)\n",
        "\n",
        "        input_df['jaccard_similarity'] = input_df.progress_apply(lambda row: len(set(word_tokenize(row['prompt_text'])) & set(word_tokenize(row['text']))) / len(set(word_tokenize(row['prompt_text'])) | set(word_tokenize(row['text']))), axis=1)\n",
        "\n",
        "\n",
        "        ###########TEXTSTAT FEARURES#############\n",
        "        input_df['flesch_reading_ease'] = input_df['text'].progress_apply(lambda x: textstat.flesch_reading_ease(x))\n",
        "        input_df['flesch_kincaid_grade'] = input_df['text'].progress_apply(lambda x: textstat.flesch_kincaid_grade(x))\n",
        "        input_df['gunning_fog'] = input_df['text'].progress_apply(lambda x: textstat.gunning_fog(x))\n",
        "        #input_df['smog_index'] = input_df['text'].progress_apply(lambda x: textstat.smog_index(x))\n",
        "        input_df['automated_readability_index'] = input_df['text'].progress_apply(lambda x: textstat.automated_readability_index(x))\n",
        "        input_df['coleman_liau_index'] = input_df['text'].progress_apply(lambda x: textstat.coleman_liau_index(x))\n",
        "        input_df['linsear_write_formula'] = input_df['text'].progress_apply(lambda x: textstat.linsear_write_formula(x))\n",
        "        input_df['dale_chall_readability_score'] = input_df['text'].progress_apply(lambda x: textstat.dale_chall_readability_score(x))\n",
        "        input_df['text_standard'] = input_df['text'].progress_apply(lambda x: textstat.text_standard(x,float_output=True))\n",
        "        input_df['spache_readability'] = input_df['text'].progress_apply(lambda x: textstat.spache_readability(x))\n",
        "        input_df['mcalpine_eflaw'] = input_df['text'].progress_apply(lambda x: textstat.mcalpine_eflaw(x))\n",
        "        input_df['reading_time'] = input_df['text'].progress_apply(lambda x: textstat.reading_time(x))\n",
        "        input_df['syllable_count'] = input_df['text'].progress_apply(lambda x: textstat.syllable_count(x))\n",
        "        input_df['polysyllabcount'] = input_df['text'].progress_apply(lambda x: textstat.polysyllabcount(x))\n",
        "        input_df['monosyllabcount'] = input_df['text'].progress_apply(lambda x: textstat.monosyllabcount(x))\n",
        "\n",
        "\n",
        "        return input_df.drop(columns=[\"summary_tokens\", \"prompt_tokens\",\"pos_ratios\",\"sentiment_scores\",\"punctuation_ratios\",\"sentiment_scores_prompt\"])\n",
        "\n",
        "preprocessor = Preprocessor(model_name=CFG.model_name,dir_model=CFG.dir_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8id7693RhaR"
      },
      "source": [
        "###Train dataset creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fml390ZWQ49D",
        "outputId": "086109bf-5ac8-46ad-f72b-92c3fd0e3cf9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     student_id prompt_id                                               text  \\\n",
              "0  000e8c3c7ddb    814d6b  The third wave was an experimentto see how peo...   \n",
              "1  0020ae56ffbf    ebad26  They would rub it up with soda to make the sme...   \n",
              "2  004e978e639e    3b9047  In Egypt, there were many occupations and soci...   \n",
              "3  005ab0199905    3b9047  The highest class was Pharaohs these people we...   \n",
              "4  0070c9e7af47    814d6b  The Third Wave developed  rapidly because the ...   \n",
              "\n",
              "    content   wording  summary_length  splling_err_num  \\\n",
              "0  0.205683  0.380538              64                2   \n",
              "1 -0.548304  0.506755              55                1   \n",
              "2  3.128928  4.231226             275                3   \n",
              "3 -0.210614 -0.471415              32                3   \n",
              "4  3.272894  3.219757             236               15   \n",
              "\n",
              "                                     prompt_question  \\\n",
              "0  Summarize how the Third Wave developed over su...   \n",
              "1  Summarize the various ways the factory would u...   \n",
              "2  In complete sentences, summarize the structure...   \n",
              "3  In complete sentences, summarize the structure...   \n",
              "4  Summarize how the Third Wave developed over su...   \n",
              "\n",
              "                prompt_title  \\\n",
              "0             The Third Wave   \n",
              "1    Excerpt from The Jungle   \n",
              "2  Egyptian Social Structure   \n",
              "3  Egyptian Social Structure   \n",
              "4             The Third Wave   \n",
              "\n",
              "                                         prompt_text  ...  coleman_liau_index  \\\n",
              "0  Background \\r\\nThe Third Wave experiment took ...  ...                9.04   \n",
              "1  With one member trimming beef in a cannery, an...  ...                4.30   \n",
              "2  Egyptian society was structured like a pyramid...  ...                9.92   \n",
              "3  Egyptian society was structured like a pyramid...  ...               10.11   \n",
              "4  Background \\r\\nThe Third Wave experiment took ...  ...               10.43   \n",
              "\n",
              "   linsear_write_formula  dale_chall_readability_score  text_standard  \\\n",
              "0                  8.375                          7.76            8.0   \n",
              "1                 13.000                          6.44            8.0   \n",
              "2                 11.200                          8.32            9.0   \n",
              "3                  4.500                         11.63            5.0   \n",
              "4                  6.625                          8.24           10.0   \n",
              "\n",
              "   spache_readability  mcalpine_eflaw  reading_time  syllable_count  \\\n",
              "0                4.54            22.0          4.20              93   \n",
              "1                5.00            38.5          2.84              56   \n",
              "2                4.95            26.8         16.69             317   \n",
              "3                3.39            11.3          1.95              37   \n",
              "4                4.32            20.2         14.98             301   \n",
              "\n",
              "   polysyllabcount  monosyllabcount  \n",
              "0                7               40  \n",
              "1                0               48  \n",
              "2               14              170  \n",
              "3                4               18  \n",
              "4               21              136  \n",
              "\n",
              "[5 rows x 51 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1d5aabb2-12d5-48bf-bb1c-1ba5c3cb82d9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>student_id</th>\n",
              "      <th>prompt_id</th>\n",
              "      <th>text</th>\n",
              "      <th>content</th>\n",
              "      <th>wording</th>\n",
              "      <th>summary_length</th>\n",
              "      <th>splling_err_num</th>\n",
              "      <th>prompt_question</th>\n",
              "      <th>prompt_title</th>\n",
              "      <th>prompt_text</th>\n",
              "      <th>...</th>\n",
              "      <th>coleman_liau_index</th>\n",
              "      <th>linsear_write_formula</th>\n",
              "      <th>dale_chall_readability_score</th>\n",
              "      <th>text_standard</th>\n",
              "      <th>spache_readability</th>\n",
              "      <th>mcalpine_eflaw</th>\n",
              "      <th>reading_time</th>\n",
              "      <th>syllable_count</th>\n",
              "      <th>polysyllabcount</th>\n",
              "      <th>monosyllabcount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000e8c3c7ddb</td>\n",
              "      <td>814d6b</td>\n",
              "      <td>The third wave was an experimentto see how peo...</td>\n",
              "      <td>0.205683</td>\n",
              "      <td>0.380538</td>\n",
              "      <td>64</td>\n",
              "      <td>2</td>\n",
              "      <td>Summarize how the Third Wave developed over su...</td>\n",
              "      <td>The Third Wave</td>\n",
              "      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n",
              "      <td>...</td>\n",
              "      <td>9.04</td>\n",
              "      <td>8.375</td>\n",
              "      <td>7.76</td>\n",
              "      <td>8.0</td>\n",
              "      <td>4.54</td>\n",
              "      <td>22.0</td>\n",
              "      <td>4.20</td>\n",
              "      <td>93</td>\n",
              "      <td>7</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0020ae56ffbf</td>\n",
              "      <td>ebad26</td>\n",
              "      <td>They would rub it up with soda to make the sme...</td>\n",
              "      <td>-0.548304</td>\n",
              "      <td>0.506755</td>\n",
              "      <td>55</td>\n",
              "      <td>1</td>\n",
              "      <td>Summarize the various ways the factory would u...</td>\n",
              "      <td>Excerpt from The Jungle</td>\n",
              "      <td>With one member trimming beef in a cannery, an...</td>\n",
              "      <td>...</td>\n",
              "      <td>4.30</td>\n",
              "      <td>13.000</td>\n",
              "      <td>6.44</td>\n",
              "      <td>8.0</td>\n",
              "      <td>5.00</td>\n",
              "      <td>38.5</td>\n",
              "      <td>2.84</td>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>004e978e639e</td>\n",
              "      <td>3b9047</td>\n",
              "      <td>In Egypt, there were many occupations and soci...</td>\n",
              "      <td>3.128928</td>\n",
              "      <td>4.231226</td>\n",
              "      <td>275</td>\n",
              "      <td>3</td>\n",
              "      <td>In complete sentences, summarize the structure...</td>\n",
              "      <td>Egyptian Social Structure</td>\n",
              "      <td>Egyptian society was structured like a pyramid...</td>\n",
              "      <td>...</td>\n",
              "      <td>9.92</td>\n",
              "      <td>11.200</td>\n",
              "      <td>8.32</td>\n",
              "      <td>9.0</td>\n",
              "      <td>4.95</td>\n",
              "      <td>26.8</td>\n",
              "      <td>16.69</td>\n",
              "      <td>317</td>\n",
              "      <td>14</td>\n",
              "      <td>170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>005ab0199905</td>\n",
              "      <td>3b9047</td>\n",
              "      <td>The highest class was Pharaohs these people we...</td>\n",
              "      <td>-0.210614</td>\n",
              "      <td>-0.471415</td>\n",
              "      <td>32</td>\n",
              "      <td>3</td>\n",
              "      <td>In complete sentences, summarize the structure...</td>\n",
              "      <td>Egyptian Social Structure</td>\n",
              "      <td>Egyptian society was structured like a pyramid...</td>\n",
              "      <td>...</td>\n",
              "      <td>10.11</td>\n",
              "      <td>4.500</td>\n",
              "      <td>11.63</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.39</td>\n",
              "      <td>11.3</td>\n",
              "      <td>1.95</td>\n",
              "      <td>37</td>\n",
              "      <td>4</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0070c9e7af47</td>\n",
              "      <td>814d6b</td>\n",
              "      <td>The Third Wave developed  rapidly because the ...</td>\n",
              "      <td>3.272894</td>\n",
              "      <td>3.219757</td>\n",
              "      <td>236</td>\n",
              "      <td>15</td>\n",
              "      <td>Summarize how the Third Wave developed over su...</td>\n",
              "      <td>The Third Wave</td>\n",
              "      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n",
              "      <td>...</td>\n",
              "      <td>10.43</td>\n",
              "      <td>6.625</td>\n",
              "      <td>8.24</td>\n",
              "      <td>10.0</td>\n",
              "      <td>4.32</td>\n",
              "      <td>20.2</td>\n",
              "      <td>14.98</td>\n",
              "      <td>301</td>\n",
              "      <td>21</td>\n",
              "      <td>136</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 51 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1d5aabb2-12d5-48bf-bb1c-1ba5c3cb82d9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1d5aabb2-12d5-48bf-bb1c-1ba5c3cb82d9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1d5aabb2-12d5-48bf-bb1c-1ba5c3cb82d9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-51db46db-1dec-44fa-a034-aa224165c2de\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-51db46db-1dec-44fa-a034-aa224165c2de')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-51db46db-1dec-44fa-a034-aa224165c2de button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# train = preprocessor.run(prompts_train, summaries_train, mode=\"train\")\n",
        "# test = preprocessor.run(prompts_test, summaries_test, mode=\"test\")\n",
        "\n",
        "train = pd.read_csv(\"/content/drive/MyDrive/CommonLit/commont-lit-train.csv\")\n",
        "\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCMOX6R8Rnwf"
      },
      "source": [
        "###Group K-Fold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eI0fzPggRsJM"
      },
      "outputs": [],
      "source": [
        "gkf = GroupKFold(n_splits=CFG.n_splits)\n",
        "\n",
        "for i, (_, val_index) in enumerate(gkf.split(train, groups=train[\"prompt_id\"])):\n",
        "    train.loc[val_index, \"fold\"] = i"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3z0L4BvRxN-"
      },
      "source": [
        "###Metrics computation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJGg_5GHRy_L"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    rmse = mean_squared_error(labels, predictions, squared=False)\n",
        "    return {\"rmse\": rmse}\n",
        "\n",
        "def compute_mcrmse(eval_pred):\n",
        "    \"\"\"\n",
        "    Calculates mean columnwise root mean squared error\n",
        "    https://www.kaggle.com/competitions/commonlit-evaluate-student-summaries/overview/evaluation\n",
        "    \"\"\"\n",
        "    preds, labels = eval_pred\n",
        "\n",
        "    col_rmse = np.sqrt(np.mean((preds - labels) ** 2, axis=0))\n",
        "    mcrmse = np.mean(col_rmse)\n",
        "\n",
        "    return {\n",
        "        \"content_rmse\": col_rmse[0],\n",
        "        \"wording_rmse\": col_rmse[1],\n",
        "        \"mcrmse\": mcrmse,\n",
        "    }\n",
        "\n",
        "def compt_score(content_true, content_pred, wording_true, wording_pred):\n",
        "    content_score = mean_squared_error(content_true, content_pred)**(1/2)\n",
        "    wording_score = mean_squared_error(wording_true, wording_pred)**(1/2)\n",
        "\n",
        "    return (content_score + wording_score)/2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZNPjFyvR-r4"
      },
      "source": [
        "###Loss defenition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBlx1oWQR-FQ"
      },
      "outputs": [],
      "source": [
        "def mcrmse_loss(y_true, y_pred):\n",
        "    colwise_mse = torch.mean(torch.square(y_true - y_pred), dim=0)\n",
        "    return torch.mean(torch.sqrt(colwise_mse), dim=0)\n",
        "\n",
        "# def mse_loss()\n",
        "#     pass\n",
        "\n",
        "class CustomTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        if \"labels\" in inputs:\n",
        "            labels = inputs.pop(\"labels\")\n",
        "        else:\n",
        "            labels = None\n",
        "\n",
        "        outputs = model(**inputs)\n",
        "        loss = mcrmse_loss(labels, outputs['logits'])\n",
        "\n",
        "        return (loss, outputs) if return_outputs else loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPma9z5BTNDe"
      },
      "source": [
        "###Regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-acPnG3pTPqX"
      },
      "outputs": [],
      "source": [
        "class ScoreRegressor:\n",
        "    def __init__(self,model_name: str,dir_model:str, model_dir: str,inputs: List[str],target_cols: List[str],hidden_dropout_prob: float,\n",
        "                attention_probs_dropout_prob: float, max_length: int,):\n",
        "\n",
        "        self.input_col = \"input\" # col name of model input after text concat sep token\n",
        "        self.input_text_cols = inputs\n",
        "        self.target_cols = target_cols\n",
        "        self.model_name = model_name\n",
        "        self.dir_model = dir_model\n",
        "        self.model_dir = model_dir\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(f\"/content/all-mpnet-base-v2-model/content/all-mpnet-base-v2-model/exp_1/fold_0/0/checkpoint-1300\")\n",
        "        self.model_config = AutoConfig.from_pretrained(f\"/content/all-mpnet-base-v2-model/content/all-mpnet-base-v2-model/exp_1/fold_0/0/checkpoint-1300\")\n",
        "\n",
        "        self.model_config.update({\n",
        "            \"hidden_dropout_prob\": hidden_dropout_prob,\n",
        "            \"attention_probs_dropout_prob\": attention_probs_dropout_prob,\n",
        "            \"num_labels\": 2,\n",
        "            \"problem_type\": \"regression\",\n",
        "        })\n",
        "\n",
        "        self.data_collator = DataCollatorWithPadding(\n",
        "            tokenizer=self.tokenizer\n",
        "        )\n",
        "\n",
        "    def concatenate_with_sep_token(self, row):\n",
        "        sep = \" \" + self.tokenizer.sep_token + \" \"\n",
        "        return sep.join(row[self.input_text_cols])\n",
        "\n",
        "    def tokenize_function(self, examples: pd.DataFrame):\n",
        "        labels = [examples[\"content\"], examples[\"wording\"]]\n",
        "        tokenized = self.tokenizer(examples[self.input_col],\n",
        "                        padding=\"max_length\",\n",
        "                        truncation=True,\n",
        "                        max_length=self.max_length)\n",
        "        return {\n",
        "            **tokenized,\n",
        "            \"labels\": labels,\n",
        "        }\n",
        "\n",
        "    def tokenize_function_test(self, examples: pd.DataFrame):\n",
        "        tokenized = self.tokenizer(examples[self.input_col],\n",
        "                        padding=\"max_length\",\n",
        "                        truncation=True,\n",
        "                        max_length=self.max_length)\n",
        "        return tokenized\n",
        "\n",
        "    # def train(self,fold: int,train_df: pd.DataFrame,valid_df: pd.DataFrame,batch_size: int,learning_rate: float,\n",
        "    #         weight_decay: float,num_train_epochs: float,save_steps: int,) -> None:\n",
        "    #     \"\"\"fine-tuning\"\"\"\n",
        "\n",
        "    #     train_df[self.input_col] = train_df.apply(self.concatenate_with_sep_token, axis=1)\n",
        "    #     valid_df[self.input_col] = valid_df.apply(self.concatenate_with_sep_token, axis=1)\n",
        "\n",
        "    #     train_df = train_df[[self.input_col] + self.target_cols]\n",
        "    #     valid_df = valid_df[[self.input_col] + self.target_cols]\n",
        "\n",
        "    #     model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    #         f\"{self.dir_model}{self.model_name}\",\n",
        "    #         config=self.model_config\n",
        "    #     )\n",
        "\n",
        "    #     train_dataset = Dataset.from_pandas(train_df, preserve_index=False)\n",
        "    #     val_dataset = Dataset.from_pandas(valid_df, preserve_index=False)\n",
        "\n",
        "    #     train_tokenized_datasets = train_dataset.map(self.tokenize_function, batched=False)\n",
        "    #     val_tokenized_datasets = val_dataset.map(self.tokenize_function, batched=False)\n",
        "\n",
        "    #     # eg. \"bert/fold_0/\"\n",
        "    #     model_fold_dir = os.path.join(self.model_dir, str(fold))\n",
        "\n",
        "    #     training_args = TrainingArguments(\n",
        "    #         output_dir=model_fold_dir,\n",
        "    #         overwrite_output_dir=True,\n",
        "    #         do_train=True,\n",
        "    #         load_best_model_at_end=True, # select best model\n",
        "    #         learning_rate=learning_rate,\n",
        "    #         per_device_train_batch_size=batch_size,\n",
        "    #         per_device_eval_batch_size=batch_size,\n",
        "    #         num_train_epochs=num_train_epochs,\n",
        "    #         weight_decay=weight_decay,\n",
        "    #         report_to='none',\n",
        "    #         greater_is_better=False,\n",
        "    #         save_strategy=\"steps\",\n",
        "    #         evaluation_strategy=\"steps\",\n",
        "    #         eval_steps=save_steps,\n",
        "    #         save_steps=save_steps,\n",
        "    #         metric_for_best_model=\"mcrmse\",\n",
        "    #         save_total_limit=1,\n",
        "    #         fp16=True,\n",
        "    #         auto_find_batch_size=True,\n",
        "    #     )\n",
        "\n",
        "    #     trainer = CustomTrainer(\n",
        "    #         model=model,\n",
        "    #         args=training_args,\n",
        "    #         train_dataset=train_tokenized_datasets,\n",
        "    #         eval_dataset=val_tokenized_datasets,\n",
        "    #         tokenizer=self.tokenizer,\n",
        "    #         compute_metrics=compute_mcrmse,\n",
        "    #         data_collator=self.data_collator,\n",
        "    #         callbacks = [EarlyStoppingCallback(early_stopping_patience=CFG.early_stopping_patience)]\n",
        "    #     )\n",
        "\n",
        "    #     trainer.train()\n",
        "\n",
        "    #     # model.save_pretrained(self.model_dir)\n",
        "    #     # self.tokenizer.save_pretrained(self.model_dir)\n",
        "\n",
        "    #     model.cpu()\n",
        "    #     del model\n",
        "    #     gc.collect()\n",
        "    #     torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "    def predict(self,test_df: pd.DataFrame,batch_size: int,fold: int,):\n",
        "        \"\"\"predict content score\"\"\"\n",
        "\n",
        "        test_df[self.input_col] = test_df.apply(self.concatenate_with_sep_token, axis=1)\n",
        "\n",
        "        test_dataset = Dataset.from_pandas(test_df[[self.input_col]], preserve_index=False)\n",
        "        test_tokenized_dataset = test_dataset.map(self.tokenize_function_test, batched=False)\n",
        "\n",
        "\n",
        "\n",
        "        checkpoint_folder = os.listdir(f\"{CFG.model_name}-model/content/{CFG.model_name}-model/exp_{EXP_NUM}/fold_{str(fold)}/{str(fold)}\")\n",
        "\n",
        "        model_fold_dir = os.path.join(f\"{CFG.model_name}-model/content/{CFG.model_name}-model/exp_{EXP_NUM}/fold_{str(fold)}/{str(fold)}\",checkpoint_folder[0])\n",
        "\n",
        "        model = AutoModelForSequenceClassification.from_pretrained(model_fold_dir)\n",
        "        model.eval()\n",
        "\n",
        "        # e.g. \"bert/fold_0/\"\n",
        "\n",
        "        test_args = TrainingArguments(\n",
        "            output_dir=model_fold_dir,\n",
        "            do_train=False,\n",
        "            do_predict=True,\n",
        "            per_device_eval_batch_size=batch_size,\n",
        "            dataloader_drop_last=False,\n",
        "            fp16=True,\n",
        "            auto_find_batch_size=True,\n",
        "        )\n",
        "\n",
        "        # init trainer\n",
        "        infer_content = CustomTrainer(\n",
        "                      model = model,\n",
        "                      tokenizer=self.tokenizer,\n",
        "                      data_collator=self.data_collator,\n",
        "                      args = test_args)\n",
        "\n",
        "        preds = infer_content.predict(test_tokenized_dataset)[0]\n",
        "        pred_df = pd.DataFrame(\n",
        "            preds,\n",
        "            columns=[\n",
        "                f\"content_pred\",\n",
        "                f\"wording_pred\"\n",
        "           ]\n",
        "        )\n",
        "\n",
        "        model.cpu()\n",
        "        del model\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        return pred_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NlF-r33-cgzM"
      },
      "outputs": [],
      "source": [
        "def validate(\n",
        "    train_df: pd.DataFrame,\n",
        "    mode: str,\n",
        "    targets: List[str],\n",
        "    inputs: List[str],\n",
        "    save_each_model: bool,\n",
        "    n_splits: int,\n",
        "    batch_size: int,\n",
        "    model_name: str,\n",
        "    dir_model:str,\n",
        "    hidden_dropout_prob: float,\n",
        "    attention_probs_dropout_prob: float,\n",
        "    max_length : int\n",
        "    ) -> pd.DataFrame:\n",
        "    \"\"\"predict oof data\"\"\"\n",
        "\n",
        "    columns = list(train_df.columns.values)\n",
        "\n",
        "    for fold in range(n_splits):\n",
        "        print(f\"fold {fold}:\")\n",
        "\n",
        "        valid_data = train_df[train_df[\"fold\"] == fold]\n",
        "\n",
        "        model_dir =  f\"{model_name}/content/{model_name}-model/exp_{EXP_NUM}/fold_{fold}\"\n",
        "\n",
        "        csr = ScoreRegressor(\n",
        "            model_name=model_name,\n",
        "            dir_model=dir_model,\n",
        "            target_cols=targets,\n",
        "            inputs= inputs,\n",
        "            model_dir = model_dir,\n",
        "            hidden_dropout_prob=hidden_dropout_prob,\n",
        "            attention_probs_dropout_prob=attention_probs_dropout_prob,\n",
        "            max_length=max_length,\n",
        "           )\n",
        "\n",
        "        pred_df = csr.predict(\n",
        "            test_df=valid_data,\n",
        "            batch_size=batch_size,\n",
        "            fold=fold\n",
        "        )\n",
        "\n",
        "        train_df.loc[valid_data.index, f\"content_{mode}_pred\"] = pred_df[f\"content_pred\"].values\n",
        "        train_df.loc[valid_data.index, f\"wording_{mode}_pred\"] = pred_df[f\"wording_pred\"].values\n",
        "\n",
        "    return train_df[columns + [f\"content_{mode}_pred\", f\"wording_{mode}_pred\"]]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Unzip folder"
      ],
      "metadata": {
        "id": "ee2SHyyRzyLm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "os.makedirs(f\"{CFG.model_name}-model\")\n",
        "with zipfile.ZipFile(f\"/content/drive/MyDrive/CommonLit/{CFG.model_name}/exp_1.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(f\"{CFG.model_name}-model\")"
      ],
      "metadata": {
        "id": "xktbjZ0bz091"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_aPdYn-ImX0L"
      },
      "source": [
        "###Train and Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "id": "AZrQ4QDreRn2",
        "outputId": "888c7aff-fb5d-4cd5-dd24-60ac7862f83f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 1:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 2:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 3:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cv content rmse: 0.5029478968441896\n",
            "cv wording rmse: 0.6541058379845475\n",
            "0.5785268674143685\n"
          ]
        }
      ],
      "source": [
        "targets = [\"wording\", \"content\"]\n",
        "mode = \"multi\"\n",
        "input_cols = [\"prompt_title\", \"prompt_question\", \"text\"]\n",
        "model_cfg = CFG\n",
        "\n",
        "train = validate(\n",
        "    train,\n",
        "    mode=mode,\n",
        "    targets=targets,\n",
        "    inputs=input_cols,\n",
        "    save_each_model=False,\n",
        "    n_splits=CFG.n_splits,\n",
        "    batch_size=model_cfg.batch_size,\n",
        "    model_name=model_cfg.model_name,\n",
        "    dir_model=model_cfg.dir_model,\n",
        "    hidden_dropout_prob=model_cfg.hidden_dropout_prob,\n",
        "    attention_probs_dropout_prob=model_cfg.attention_probs_dropout_prob,\n",
        "    max_length=model_cfg.max_length\n",
        ")\n",
        "r=0\n",
        "# set validate result\n",
        "for target in [\"content\", \"wording\"]:\n",
        "    rmse = mean_squared_error(train[target], train[f\"{target}_{mode}_pred\"], squared=False)\n",
        "    r += rmse\n",
        "    print(f\"cv {target} rmse: {rmse}\")\n",
        "\n",
        "print(r/2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "targets = [\"content\", \"wording\"]\n",
        "\n",
        "drop_columns = [\"fold\", \"student_id\", \"prompt_id\", \"text\",\n",
        "                \"prompt_question\", \"prompt_title\",\n",
        "                \"prompt_text\",\"prompt_length\",\n",
        "                \"avg_word_length\",\"semicolon_count\",\"neg\",\"neu\",\"pos\",\"compound\",\n",
        "                \"exclamation_count\",\"question_count\",\"punctuation_sum\",\"neg_prompt\",\"neu_prompt\",\"pos_prompt\",\n",
        "                \"compound_prompt\",\"flesch_reading_ease\",\"flesch_kincaid_grade\",\"gunning_fog\",\"automated_readability_index\",\n",
        "                \"coleman_liau_index\",\"linsear_write_formula\",\"dale_chall_readability_score\",\"text_standard\",\"spache_readability\",\n",
        "                \"mcalpine_eflaw\"\n",
        "               ] + targets"
      ],
      "metadata": {
        "id": "Q62wwztV4S6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_dict = {}\n",
        "\n",
        "for target in targets:\n",
        "    models = []\n",
        "\n",
        "    for fold in range(CFG.n_splits):\n",
        "\n",
        "        X_train_cv = train[train[\"fold\"] != fold].drop(columns=drop_columns)\n",
        "        y_train_cv = train[train[\"fold\"] != fold][target]\n",
        "\n",
        "        X_eval_cv = train[train[\"fold\"] == fold].drop(columns=drop_columns)\n",
        "        y_eval_cv = train[train[\"fold\"] == fold][target]\n",
        "\n",
        "        dtrain = lgb.Dataset(X_train_cv, label=y_train_cv)\n",
        "        dval = lgb.Dataset(X_eval_cv, label=y_eval_cv)\n",
        "\n",
        "        params = {\n",
        "                  'boosting_type': 'gbdt',\n",
        "                  'random_state': 42,\n",
        "                  'objective': 'regression',\n",
        "                  'metric': 'rmse',\n",
        "                  'learning_rate': 0.048,\n",
        "                  'lambda_l1': 0.0,\n",
        "                  'lambda_l2': 0.011\n",
        "                  }\n",
        "\n",
        "        evaluation_results = {}\n",
        "        model = lgb.train(params,\n",
        "                          num_boost_round=10000,\n",
        "                            #categorical_feature = categorical_features,\n",
        "                          valid_names=['train', 'valid'],\n",
        "                          train_set=dtrain,\n",
        "                          valid_sets=dval,\n",
        "                          callbacks=[\n",
        "                              lgb.early_stopping(stopping_rounds=30, verbose=True),\n",
        "                               lgb.log_evaluation(100),\n",
        "                              lgb.callback.record_evaluation(evaluation_results)\n",
        "                            ],\n",
        "                          )\n",
        "        models.append(model)\n",
        "\n",
        "    model_dict[target] = models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWkrJOgQ4ea9",
        "outputId": "827828e9-5942-4566-a2da-cac28f15ed4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000604 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3004\n",
            "[LightGBM] [Info] Number of data points in the train set: 5108, number of used features: 21\n",
            "[LightGBM] [Info] Start training from score 0.017606\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "Early stopping, best iteration is:\n",
            "[50]\ttrain's rmse: 0.424919\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000523 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2926\n",
            "[LightGBM] [Info] Number of data points in the train set: 5156, number of used features: 21\n",
            "[LightGBM] [Info] Start training from score -0.039959\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[100]\ttrain's rmse: 0.483953\n",
            "Early stopping, best iteration is:\n",
            "[142]\ttrain's rmse: 0.483025\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000459 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2927\n",
            "[LightGBM] [Info] Number of data points in the train set: 5169, number of used features: 21\n",
            "[LightGBM] [Info] Start training from score 0.013356\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "Early stopping, best iteration is:\n",
            "[62]\ttrain's rmse: 0.423408\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000593 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3022\n",
            "[LightGBM] [Info] Number of data points in the train set: 6062, number of used features: 21\n",
            "[LightGBM] [Info] Start training from score -0.044904\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[100]\ttrain's rmse: 0.462343\n",
            "Early stopping, best iteration is:\n",
            "[101]\ttrain's rmse: 0.462154\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000459 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3004\n",
            "[LightGBM] [Info] Number of data points in the train set: 5108, number of used features: 21\n",
            "[LightGBM] [Info] Start training from score -0.031791\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[100]\ttrain's rmse: 0.539541\n",
            "Early stopping, best iteration is:\n",
            "[75]\ttrain's rmse: 0.536525\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000493 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2926\n",
            "[LightGBM] [Info] Number of data points in the train set: 5156, number of used features: 21\n",
            "[LightGBM] [Info] Start training from score -0.060941\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "Early stopping, best iteration is:\n",
            "[65]\ttrain's rmse: 0.633183\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000443 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2927\n",
            "[LightGBM] [Info] Number of data points in the train set: 5169, number of used features: 21\n",
            "[LightGBM] [Info] Start training from score 0.028040\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[100]\ttrain's rmse: 0.503635\n",
            "Early stopping, best iteration is:\n",
            "[103]\ttrain's rmse: 0.502792\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000524 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3022\n",
            "[LightGBM] [Info] Number of data points in the train set: 6062, number of used features: 21\n",
            "[LightGBM] [Info] Start training from score -0.168933\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[100]\ttrain's rmse: 0.634303\n",
            "Early stopping, best iteration is:\n",
            "[112]\ttrain's rmse: 0.633225\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cv\n",
        "rmses = []\n",
        "\n",
        "for target in targets:\n",
        "    models = model_dict[target]\n",
        "\n",
        "    preds = []\n",
        "    trues = []\n",
        "\n",
        "    for fold, model in enumerate(models):\n",
        "        # ilocで取り出す行を指定\n",
        "        X_eval_cv = train[train[\"fold\"] == fold].drop(columns=drop_columns)\n",
        "        y_eval_cv = train[train[\"fold\"] == fold][target]\n",
        "\n",
        "        pred = model.predict(X_eval_cv)\n",
        "\n",
        "        trues.extend(y_eval_cv)\n",
        "        preds.extend(pred)\n",
        "\n",
        "    rmse = np.sqrt(mean_squared_error(trues, preds))\n",
        "    print(f\"{target}_rmse : {rmse}\")\n",
        "    rmses = rmses + [rmse]\n",
        "\n",
        "print(f\"mcrmse : {sum(rmses) / len(rmses)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PMPS6nV4iPj",
        "outputId": "8d4f68ca-5326-4dcc-8826-3510b959e0f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content_rmse : 0.4472987686217713\n",
            "wording_rmse : 0.57202025599554\n",
            "mcrmse : 0.5096595123086556\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NibcxKIvPGbY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}